{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b183d1",
   "metadata": {},
   "source": [
    "# ğŸš€ **Ready for Google Colab!** \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JishnuPG-tech/neural-network-appliance-energy-prediction/blob/main/notebooks/04_model_evaluation.ipynb)\n",
    "\n",
    "**Click the badge above to open this notebook in Google Colab instantly!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99911b0a",
   "metadata": {},
   "source": [
    "# ğŸ“Š Neural Network Model Evaluation & Performance Analysis\n",
    "\n",
    "**Comprehensive TensorFlow/Keras Model Assessment**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JishnuPG-tech/neural-network-appliance-energy-prediction/blob/main/notebooks/04_model_evaluation.ipynb)\n",
    "\n",
    "## ğŸ“‹ Evaluation Overview\n",
    "\n",
    "This notebook provides comprehensive evaluation of our neural network model for appliance energy prediction, including performance metrics, visualizations, and insights.\n",
    "\n",
    "### ğŸ¯ Evaluation Objectives:\n",
    "- **Performance Metrics**: MSE, MAE, RÂ², MAPE for regression analysis\n",
    "- **Visual Analysis**: Prediction vs actual plots, residual analysis\n",
    "- **Statistical Tests**: Model significance and confidence intervals\n",
    "- **Error Analysis**: Understand prediction patterns and limitations\n",
    "- **Model Interpretation**: Feature importance and decision insights\n",
    "\n",
    "### ğŸ“ˆ Key Metrics:\n",
    "- **Mean Squared Error (MSE)**: Primary loss function\n",
    "- **Mean Absolute Error (MAE)**: Interpretable error metric\n",
    "- **R-squared (RÂ²)**: Explained variance measure\n",
    "- **Mean Absolute Percentage Error (MAPE)**: Relative error assessment\n",
    "- **Root Mean Squared Error (RMSE)**: Standard deviation of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11997142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ Environment Setup for Google Colab and Local Development\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸŒŸ Running in Google Colab!\")\n",
    "    \n",
    "    # Clone repository if in Colab\n",
    "    if not os.path.exists('/content/neural-network-appliance-energy-prediction'):\n",
    "        print(\"ğŸ“ Cloning repository...\")\n",
    "        !git clone https://github.com/JishnuPG-tech/neural-network-appliance-energy-prediction.git\n",
    "        os.chdir('/content/neural-network-appliance-energy-prediction')\n",
    "        print(\"âœ… Repository cloned successfully!\")\n",
    "    else:\n",
    "        os.chdir('/content/neural-network-appliance-energy-prediction')\n",
    "        print(\"âœ… Using existing repository!\")\n",
    "        \n",
    "    # Install required packages for Colab\n",
    "    print(\"ğŸ“¦ Installing evaluation dependencies...\")\n",
    "    !pip install tensorflow==2.13.0 pandas numpy matplotlib seaborn plotly scikit-learn\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» Running in local environment!\")\n",
    "    \n",
    "    # Navigate to project root if running locally\n",
    "    if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "        os.chdir('..')\n",
    "    \n",
    "print(f\"ğŸ“ Current working directory: {os.getcwd()}\")\n",
    "print(f\"ğŸ Python version: {sys.version}\")\n",
    "\n",
    "# Environment confirmation\n",
    "if IN_COLAB:\n",
    "    print(\"\\nğŸš€ Google Colab environment ready for model evaluation!\")\n",
    "else:\n",
    "    print(\"\\nğŸ’» Local development environment ready for evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50094e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š Import Libraries for Model Evaluation\n",
    "\n",
    "# TensorFlow/Keras for model loading and evaluation\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    mean_absolute_error, \n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Statistical Libraries\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ğŸ“Š All evaluation libraries imported successfully!\")\n",
    "print(\"ğŸ¯ Ready for comprehensive model assessment!\")\n",
    "print(f\"ğŸ”¥ TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c5571",
   "metadata": {},
   "source": [
    "# ğŸ“Š Model Evaluation and Performance Analysis\n",
    "\n",
    "**Comprehensive Analysis of Neural Network Performance for Appliance Energy Prediction**\n",
    "\n",
    "This notebook provides in-depth evaluation of our trained neural network model. You'll learn how to assess model performance, identify strengths and weaknesses, and validate the model for real-world deployment.\n",
    "\n",
    "## ğŸ¯ What You'll Learn\n",
    "1. **Load and test** the trained neural network model\n",
    "2. **Comprehensive evaluation** using multiple metrics\n",
    "3. **Cross-validation** for robust performance assessment\n",
    "4. **Feature importance** analysis\n",
    "5. **Model interpretation** and business insights\n",
    "6. **Deployment readiness** assessment\n",
    "\n",
    "## ğŸ“Š Evaluation Approach\n",
    "- **Accuracy Metrics**: RÂ², MSE, MAE, MAPE\n",
    "- **Visual Analysis**: Prediction plots, residual analysis\n",
    "- **Statistical Tests**: Distribution analysis, bias detection\n",
    "- **Business Metrics**: Cost implications, practical accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb718e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for neural network evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Machine learning evaluation libraries\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro, pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"\ude80 NEURAL NETWORK MODEL EVALUATION SETUP\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"ğŸ“Š TensorFlow: {tf.__version__}\")\n",
    "print(f\"ğŸ”¢ NumPy: {np.__version__}\")\n",
    "print(f\"ğŸ“ˆ Pandas: {pd.__version__}\")\n",
    "print(f\"\udcca Matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"ğŸ¨ Seaborn: {sns.__version__}\")\n",
    "print(\"ğŸ§  Ready for comprehensive neural network evaluation!\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740bc93",
   "metadata": {},
   "source": [
    "## 1. ğŸ”„ Loading Trained Model and Data\n",
    "\n",
    "Let's load our trained neural network and prepare the data for comprehensive evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained neural network model and data\n",
    "print(\"\udcc2 LOADING TRAINED MODEL & DATA\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Define paths\n",
    "models_dir = Path('../models')\n",
    "processed_dir = Path('../data/processed')\n",
    "\n",
    "# Load the trained neural network model\n",
    "model_path = models_dir / 'appliance_energy_model.h5'\n",
    "\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "    print(f\"âœ… Neural network model loaded successfully\")\n",
    "    print(f\"ğŸ“ Model path: {model_path}\")\n",
    "    \n",
    "    # Display model architecture summary\n",
    "    print(f\"\\nğŸ§  Model Architecture:\")\n",
    "    print(f\"   ğŸ“Š Total parameters: {model.count_params():,}\")\n",
    "    print(f\"   ğŸ—ï¸  Layers: {len(model.layers)}\")\n",
    "    print(f\"   ğŸ“¥ Input shape: {model.input_shape}\")\n",
    "    print(f\"   ğŸ“¤ Output shape: {model.output_shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading model: {e}\")\n",
    "    print(\"ğŸ“ Please run the neural network training notebook first!\")\n",
    "    raise\n",
    "\n",
    "# Load model metadata\n",
    "try:\n",
    "    with open(models_dir / 'model_metadata.json', 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    print(f\"âœ… Model metadata loaded\")\n",
    "    \n",
    "    print(f\"\\n\udccb Training Information:\")\n",
    "    print(f\"   ğŸ“… Training date: {metadata['training_date']}\")\n",
    "    print(f\"   â±ï¸  Training duration: {metadata['training_duration']}\")\n",
    "    print(f\"   ğŸ”„ Epochs trained: {metadata['epochs_trained']}\")\n",
    "    print(f\"   ğŸ“¦ Batch size: {metadata['batch_size']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Metadata not found: {e}\")\n",
    "    metadata = {}\n",
    "\n",
    "# Load test data\n",
    "try:\n",
    "    X_test = pd.read_csv(processed_dir / 'X_test_scaled.csv')\n",
    "    y_test = pd.read_csv(processed_dir / 'y_test.csv').values.ravel()\n",
    "    \n",
    "    # Also load train and validation for comprehensive analysis\n",
    "    X_train = pd.read_csv(processed_dir / 'X_train_scaled.csv')\n",
    "    y_train = pd.read_csv(processed_dir / 'y_train.csv').values.ravel()\n",
    "    X_val = pd.read_csv(processed_dir / 'X_val_scaled.csv')\n",
    "    y_val = pd.read_csv(processed_dir / 'y_val.csv').values.ravel()\n",
    "    \n",
    "    print(f\"âœ… Test data loaded successfully\")\n",
    "    print(f\"ğŸ“Š Test set shape: {X_test.shape}\")\n",
    "    print(f\"ğŸ¯ Test target range: {y_test.min():.1f} - {y_test.max():.1f} kWh/month\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading test data: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\nğŸ¯ Ready for comprehensive model evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for comprehensive evaluation\n",
    "print(\"\udd2e GENERATING PREDICTIONS FOR EVALUATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Generate predictions on all datasets\n",
    "print(\"ğŸ¯ Making predictions on all datasets...\")\n",
    "\n",
    "y_train_pred = model.predict(X_train, verbose=0).flatten()\n",
    "y_val_pred = model.predict(X_val, verbose=0).flatten() \n",
    "y_test_pred = model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "print(f\"âœ… Predictions generated:\")\n",
    "print(f\"   ğŸ‹ï¸ Training predictions: {len(y_train_pred)}\")\n",
    "print(f\"   âœ… Validation predictions: {len(y_val_pred)}\")\n",
    "print(f\"   ğŸ§ª Test predictions: {len(y_test_pred)}\")\n",
    "\n",
    "# Quick prediction statistics\n",
    "print(f\"\\nğŸ“Š Prediction Statistics:\")\n",
    "for name, y_true, y_pred in [('Train', y_train, y_train_pred), \n",
    "                            ('Val', y_val, y_val_pred), \n",
    "                            ('Test', y_test, y_test_pred)]:\n",
    "    print(f\"   {name} - Actual: {y_true.min():.1f}-{y_true.max():.1f}, Predicted: {y_pred.min():.1f}-{y_pred.max():.1f}\")\n",
    "\n",
    "# Check for any prediction anomalies\n",
    "def check_prediction_anomalies(y_pred, dataset_name):\n",
    "    \"\"\"Check for common prediction issues\"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    # Check for NaN or infinite values\n",
    "    if np.isnan(y_pred).any():\n",
    "        issues.append(\"Contains NaN values\")\n",
    "    if np.isinf(y_pred).any():\n",
    "        issues.append(\"Contains infinite values\")\n",
    "        \n",
    "    # Check for negative predictions (energy consumption should be positive)\n",
    "    negative_count = (y_pred < 0).sum()\n",
    "    if negative_count > 0:\n",
    "        issues.append(f\"{negative_count} negative predictions\")\n",
    "        \n",
    "    # Check for unrealistic high values\n",
    "    high_threshold = 1000  # 1000 kWh/month seems unreasonably high\n",
    "    high_count = (y_pred > high_threshold).sum()\n",
    "    if high_count > 0:\n",
    "        issues.append(f\"{high_count} unusually high predictions (>{high_threshold} kWh)\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"âš ï¸  {dataset_name} prediction issues: {', '.join(issues)}\")\n",
    "    else:\n",
    "        print(f\"âœ… {dataset_name} predictions: No anomalies detected\")\n",
    "\n",
    "# Check all datasets for anomalies\n",
    "check_prediction_anomalies(y_train_pred, \"Training\")\n",
    "check_prediction_anomalies(y_val_pred, \"Validation\")\n",
    "check_prediction_anomalies(y_test_pred, \"Test\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Prediction generation completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd98a37",
   "metadata": {},
   "source": [
    "## 2. ğŸ“Š Comprehensive Performance Metrics\n",
    "\n",
    "Let's calculate and analyze multiple performance metrics to get a complete picture of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca663768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive performance metrics calculation\n",
    "print(\"ğŸ“Š COMPREHENSIVE PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "def calculate_comprehensive_metrics(y_true, y_pred, dataset_name):\n",
    "    \"\"\"Calculate comprehensive evaluation metrics for neural network\"\"\"\n",
    "    \n",
    "    # Basic regression metrics\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # MAPE with zero-division protection\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), 1e-8))) * 100\n",
    "    \n",
    "    # Additional metrics\n",
    "    max_error = np.max(np.abs(y_true - y_pred))\n",
    "    std_error = np.std(y_true - y_pred)\n",
    "    \n",
    "    # Correlation coefficient\n",
    "    correlation, p_value = pearsonr(y_true, y_pred)\n",
    "    \n",
    "    # Percentage of predictions within tolerance\n",
    "    tolerance_5_percent = np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-8)) <= 0.05) * 100\n",
    "    tolerance_10_percent = np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-8)) <= 0.10) * 100\n",
    "    tolerance_20_percent = np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-8)) <= 0.20) * 100\n",
    "    \n",
    "    metrics = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'RÂ²': r2,\n",
    "        'MAPE': mape,\n",
    "        'Max_Error': max_error,\n",
    "        'Std_Error': std_error,\n",
    "        'Correlation': correlation,\n",
    "        'Corr_P_Value': p_value,\n",
    "        'Within_5%': tolerance_5_percent,\n",
    "        'Within_10%': tolerance_10_percent,\n",
    "        'Within_20%': tolerance_20_percent\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for all datasets\n",
    "train_metrics = calculate_comprehensive_metrics(y_train, y_train_pred, \"Training\")\n",
    "val_metrics = calculate_comprehensive_metrics(y_val, y_val_pred, \"Validation\")\n",
    "test_metrics = calculate_comprehensive_metrics(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# Create comprehensive metrics DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Training': train_metrics,\n",
    "    'Validation': val_metrics,\n",
    "    'Testing': test_metrics\n",
    "}).round(4)\n",
    "\n",
    "print(\"ğŸ“‹ COMPREHENSIVE PERFORMANCE METRICS:\")\n",
    "print(\"=\" * 40)\n",
    "display(metrics_df)\n",
    "\n",
    "# Performance analysis\n",
    "print(f\"\\nğŸ¯ PERFORMANCE ANALYSIS:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Overall accuracy assessment\n",
    "test_accuracy = test_metrics['RÂ²'] * 100\n",
    "print(f\"ğŸ“Š Overall Test Accuracy: {test_accuracy:.1f}% (RÂ² = {test_metrics['RÂ²']:.4f})\")\n",
    "\n",
    "# Error analysis\n",
    "print(f\"\udcc9 Prediction Errors on Test Set:\")\n",
    "print(f\"   RMSE: {test_metrics['RMSE']:.2f} kWh/month\")\n",
    "print(f\"   MAE: {test_metrics['MAE']:.2f} kWh/month\")\n",
    "print(f\"   MAPE: {test_metrics['MAPE']:.1f}%\")\n",
    "print(f\"   Max Error: {test_metrics['Max_Error']:.2f} kWh/month\")\n",
    "\n",
    "# Tolerance analysis\n",
    "print(f\"\\nğŸ¯ Prediction Tolerance Analysis:\")\n",
    "print(f\"   Within 5% error: {test_metrics['Within_5%']:.1f}% of predictions\")\n",
    "print(f\"   Within 10% error: {test_metrics['Within_10%']:.1f}% of predictions\")\n",
    "print(f\"   Within 20% error: {test_metrics['Within_20%']:.1f}% of predictions\")\n",
    "\n",
    "# Overfitting assessment\n",
    "r2_diff = train_metrics['RÂ²'] - test_metrics['RÂ²']\n",
    "mae_diff = test_metrics['MAE'] - train_metrics['MAE']\n",
    "\n",
    "print(f\"\\nğŸ§ Overfitting Assessment:\")\n",
    "print(f\"   RÂ² difference (Train - Test): {r2_diff:.4f}\")\n",
    "print(f\"   MAE difference (Test - Train): {mae_diff:.4f}\")\n",
    "\n",
    "if r2_diff > 0.1:\n",
    "    print(\"   âš ï¸  Significant overfitting detected\")\n",
    "elif r2_diff > 0.05:\n",
    "    print(\"   ğŸŸ¡ Minor overfitting detected\")\n",
    "else:\n",
    "    print(\"   âœ… No significant overfitting\")\n",
    "\n",
    "# Model quality assessment\n",
    "if test_metrics['RÂ²'] >= 0.9:\n",
    "    quality = \"Excellent\"\n",
    "elif test_metrics['RÂ²'] >= 0.8:\n",
    "    quality = \"Good\"\n",
    "elif test_metrics['RÂ²'] >= 0.7:\n",
    "    quality = \"Fair\"\n",
    "else:\n",
    "    quality = \"Poor\"\n",
    "\n",
    "print(f\"\\nğŸ† Overall Model Quality: {quality}\")\n",
    "print(f\"ğŸ“Š Model meets production requirements: {'âœ…' if test_metrics['RÂ²'] >= 0.8 else 'âŒ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05ca3e",
   "metadata": {},
   "source": [
    "## 3. ğŸ“ˆ Visual Performance Analysis\n",
    "\n",
    "Let's create comprehensive visualizations to understand model performance across different dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance visualization dashboard\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=[\n",
    "        'ğŸ¯ Predicted vs Actual', 'ğŸ“Š Residual Distribution',\n",
    "        'ğŸ“ˆ Residuals vs Predicted', 'âš¡ Performance by Appliance',\n",
    "        'ğŸŒ¡ï¸ Performance by Season', 'ğŸ’° Error Distribution'\n",
    "    ],\n",
    "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    ")\n",
    "\n",
    "# Plot 1: Predicted vs Actual\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_target, y=y_pred_all,\n",
    "        mode='markers',\n",
    "        name='Predictions',\n",
    "        marker=dict(color='blue', size=4, opacity=0.6)\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Perfect prediction line\n",
    "min_val, max_val = y_target.min(), y_target.max()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[min_val, max_val], y=[min_val, max_val],\n",
    "        mode='lines',\n",
    "        name='Perfect Prediction',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Plot 2: Residual Distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=residuals,\n",
    "        nbinsx=30,\n",
    "        name='Residuals',\n",
    "        marker_color='lightblue'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Plot 3: Residuals vs Predicted\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_pred_all, y=residuals,\n",
    "        mode='markers',\n",
    "        name='Residual Pattern',\n",
    "        marker=dict(color='green', size=4, opacity=0.6)\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Zero line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[y_pred_all.min(), y_pred_all.max()], y=[0, 0],\n",
    "        mode='lines',\n",
    "        name='Zero Error',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Plot 4: Performance by Appliance\n",
    "appliance_mae = df.groupby('appliance_type').apply(\n",
    "    lambda x: mean_absolute_error(\n",
    "        x['daily_consumption_kwh'], \n",
    "        y_pred_all[x.index]\n",
    "    )\n",
    ").sort_values()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=appliance_mae.index,\n",
    "        y=appliance_mae.values,\n",
    "        name='MAE by Appliance',\n",
    "        marker_color='orange'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Plot 5: Performance by Season\n",
    "season_mae = df.groupby('season').apply(\n",
    "    lambda x: mean_absolute_error(\n",
    "        x['daily_consumption_kwh'], \n",
    "        y_pred_all[x.index]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=season_mae.index,\n",
    "        y=season_mae.values,\n",
    "        name='MAE by Season',\n",
    "        marker_color='lightcoral'\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Plot 6: Error Distribution by Range\n",
    "error_ranges = ['0-0.5', '0.5-1.0', '1.0-2.0', '2.0+']\n",
    "error_counts = [\n",
    "    np.sum(np.abs(residuals) <= 0.5),\n",
    "    np.sum((np.abs(residuals) > 0.5) & (np.abs(residuals) <= 1.0)),\n",
    "    np.sum((np.abs(residuals) > 1.0) & (np.abs(residuals) <= 2.0)),\n",
    "    np.sum(np.abs(residuals) > 2.0)\n",
    "]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=error_ranges,\n",
    "        y=error_counts,\n",
    "        name='Error Distribution',\n",
    "        marker_color='lightgreen'\n",
    "    ),\n",
    "    row=3, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1200,\n",
    "    showlegend=False,\n",
    "    title_text=\"ğŸ“Š Comprehensive Model Performance Dashboard\",\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "# Update axes labels\n",
    "fig.update_xaxes(title_text=\"Actual Consumption (kWh)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Predicted Consumption (kWh)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Residuals (kWh)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Predicted Consumption (kWh)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Residuals (kWh)\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Appliance Type\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"MAE (kWh)\", row=2, col=2)\n",
    "fig.update_xaxes(title_text=\"Season\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"MAE (kWh)\", row=3, col=1)\n",
    "fig.update_xaxes(title_text=\"Error Range (kWh)\", row=3, col=2)\n",
    "fig.update_yaxes(title_text=\"Count\", row=3, col=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"ğŸ“Š VISUAL ANALYSIS INSIGHTS:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"ğŸ¯ Best performing appliance: {appliance_mae.index[0]} (MAE: {appliance_mae.iloc[0]:.3f} kWh)\")\n",
    "print(f\"âš ï¸ Challenging appliance: {appliance_mae.index[-1]} (MAE: {appliance_mae.iloc[-1]:.3f} kWh)\")\n",
    "print(f\"ğŸŒ¡ï¸ Best season: {season_mae.idxmin()} (MAE: {season_mae.min():.3f} kWh)\")\n",
    "print(f\"ğŸ“ˆ Most predictions ({error_counts[0]}/{len(residuals)}) have <0.5 kWh error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d740905",
   "metadata": {},
   "source": [
    "## 4. ğŸ’¼ Business Impact Analysis\n",
    "\n",
    "Let's analyze the practical business implications of our model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f295728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business impact analysis\n",
    "print(\"ğŸ’¼ BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Cost implications\n",
    "electricity_rate = 6.0  # INR per kWh (average Indian rate)\n",
    "days_per_month = 30\n",
    "\n",
    "# Calculate monthly cost errors\n",
    "monthly_cost_errors = np.abs(residuals) * electricity_rate * days_per_month\n",
    "avg_monthly_cost_error = np.mean(monthly_cost_errors)\n",
    "max_monthly_cost_error = np.max(monthly_cost_errors)\n",
    "\n",
    "# Calculate total consumption and costs\n",
    "total_actual_monthly = y_target.sum() * days_per_month\n",
    "total_predicted_monthly = y_pred_all.sum() * days_per_month\n",
    "total_actual_cost = total_actual_monthly * electricity_rate\n",
    "total_predicted_cost = total_predicted_monthly * electricity_rate\n",
    "\n",
    "print(\"ğŸ’° COST IMPACT ANALYSIS:\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"   ğŸ“Š Average monthly cost error: â‚¹{avg_monthly_cost_error:.2f} per appliance\")\n",
    "print(f\"   ğŸ“ˆ Maximum monthly cost error: â‚¹{max_monthly_cost_error:.2f} per appliance\")\n",
    "print(f\"   ğŸ“‹ Median monthly cost error: â‚¹{np.median(monthly_cost_errors):.2f} per appliance\")\n",
    "\n",
    "# Error by appliance type\n",
    "print(\"\\nâš¡ ERROR BY APPLIANCE TYPE:\")\n",
    "print(\"-\" * 30)\n",
    "for appliance in df['appliance_type'].unique():\n",
    "    mask = df['appliance_type'] == appliance\n",
    "    appliance_errors = monthly_cost_errors[mask]\n",
    "    avg_error = np.mean(appliance_errors)\n",
    "    print(f\"   ğŸ“Š {appliance}: â‚¹{avg_error:.2f}/month average error\")\n",
    "\n",
    "# Model reliability assessment\n",
    "print(\"\\nğŸ›¡ï¸ MODEL RELIABILITY ASSESSMENT:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "reliable_predictions = np.sum(np.abs(residuals) <= 0.5) / len(residuals) * 100\n",
    "acceptable_predictions = np.sum(np.abs(residuals) <= 1.0) / len(residuals) * 100\n",
    "\n",
    "print(f\"   âœ… Highly reliable predictions (â‰¤0.5 kWh error): {reliable_predictions:.1f}%\")\n",
    "print(f\"   ğŸ‘ Acceptable predictions (â‰¤1.0 kWh error): {acceptable_predictions:.1f}%\")\n",
    "\n",
    "# Business recommendations\n",
    "print(\"\\nğŸ“‹ BUSINESS RECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "if reliable_predictions > 70:\n",
    "    print(\"   ğŸŒŸ Excellent reliability - ready for production deployment\")\n",
    "    print(\"   âœ… Can be used for energy planning and cost estimation\")\n",
    "elif reliable_predictions > 50:\n",
    "    print(\"   ğŸ‘ Good reliability - suitable for most applications\")\n",
    "    print(\"   âš ï¸ Consider confidence intervals for critical decisions\")\n",
    "else:\n",
    "    print(\"   âŒ Limited reliability - needs improvement before deployment\")\n",
    "    print(\"   ğŸ”§ Consider collecting more data or feature engineering\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ For household energy management, this model can save families\")\n",
    "print(f\"   an average of â‚¹{avg_monthly_cost_error:.0f}/month in prediction accuracy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba26ff7",
   "metadata": {},
   "source": [
    "## 5. ğŸ“ Model Evaluation Summary and Recommendations\n",
    "\n",
    "Let's create a comprehensive summary of our model evaluation findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive evaluation summary\n",
    "print(\"ğŸ“ COMPREHENSIVE MODEL EVALUATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Executive Summary\n",
    "print(\"ğŸ¯ EXECUTIVE SUMMARY:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"   ğŸ§  Model Type: Neural Network (TensorFlow/Keras)\")\n",
    "print(f\"   ğŸ“Š Dataset Size: {len(df):,} appliances from {df['household_id'].nunique()} households\")\n",
    "print(f\"   ğŸ¯ Target Variable: Daily Energy Consumption (kWh)\")\n",
    "print(f\"   ğŸ“ˆ Overall Performance: {performance_level}\")\n",
    "print(f\"   ğŸ“Š Accuracy (RÂ²): {r2:.3f} ({r2*100:.1f}% variance explained)\")\n",
    "print(f\"   ğŸ’° Average Cost Error: â‚¹{avg_monthly_cost_error:.2f}/month per appliance\")\n",
    "\n",
    "# Strengths\n",
    "print(\"\\nğŸ’ª MODEL STRENGTHS:\")\n",
    "print(\"-\" * 20)\n",
    "strengths = []\n",
    "if r2 > 0.7:\n",
    "    strengths.append(\"High predictive accuracy\")\n",
    "if within_20_percent > 80:\n",
    "    strengths.append(\"Most predictions within 20% error\")\n",
    "if abs(mean_residual) < 0.1:\n",
    "    strengths.append(\"Low systematic bias\")\n",
    "\n",
    "for i, strength in enumerate(strengths, 1):\n",
    "    print(f\"   {i}. âœ… {strength}\")\n",
    "\n",
    "# Deployment Readiness\n",
    "print(\"\\nğŸš€ DEPLOYMENT READINESS:\")\n",
    "print(\"-\" * 25)\n",
    "deployment_score = 0\n",
    "max_score = 5\n",
    "\n",
    "# Scoring criteria\n",
    "if r2 > 0.7: deployment_score += 1\n",
    "if within_20_percent > 75: deployment_score += 1\n",
    "if abs(mean_residual) < 0.2: deployment_score += 1\n",
    "if avg_monthly_cost_error < 100: deployment_score += 1\n",
    "if reliable_predictions > 60: deployment_score += 1\n",
    "\n",
    "deployment_percentage = (deployment_score / max_score) * 100\n",
    "\n",
    "print(f\"   ğŸ“Š Deployment Score: {deployment_score}/{max_score} ({deployment_percentage:.0f}%)\")\n",
    "\n",
    "if deployment_percentage >= 80:\n",
    "    readiness = \"ğŸŸ¢ Ready for Production\"\n",
    "    recommendation = \"Deploy with confidence\"\n",
    "elif deployment_percentage >= 60:\n",
    "    readiness = \"ğŸŸ¡ Ready with Monitoring\"\n",
    "    recommendation = \"Deploy with careful monitoring\"\n",
    "else:\n",
    "    readiness = \"ğŸ”´ Needs Improvement\"\n",
    "    recommendation = \"Improve before deployment\"\n",
    "\n",
    "print(f\"   ğŸ¯ Status: {readiness}\")\n",
    "print(f\"   ğŸ’¡ Recommendation: {recommendation}\")\n",
    "\n",
    "# Final Recommendations\n",
    "print(\"\\nğŸ“‹ FINAL RECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"   1. ğŸ“± Integrate model into web application for user predictions\")\n",
    "print(\"   2. ğŸ”„ Implement model monitoring and performance tracking\")\n",
    "print(\"   3. ğŸ“Š Collect user feedback to improve future versions\")\n",
    "print(\"   4. âš–ï¸ Add confidence intervals for critical business decisions\")\n",
    "print(\"   5. ğŸ”§ Consider ensemble methods for improved robustness\")\n",
    "\n",
    "# Save evaluation results\n",
    "evaluation_results = {\n",
    "    'r2_score': r2,\n",
    "    'mae': mae,\n",
    "    'rmse': rmse,\n",
    "    'mape': mape,\n",
    "    'within_20_percent': within_20_percent,\n",
    "    'avg_monthly_cost_error': avg_monthly_cost_error,\n",
    "    'deployment_score': deployment_score,\n",
    "    'deployment_percentage': deployment_percentage,\n",
    "    'best_appliance': appliance_mae.index[0],\n",
    "    'worst_appliance': appliance_mae.index[-1]\n",
    "}\n",
    "\n",
    "joblib.dump(evaluation_results, '../models/evaluation_results.pkl')\n",
    "print(\"\\nğŸ’¾ Evaluation results saved for future reference!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ‰ MODEL EVALUATION COMPLETE!\")\n",
    "print(f\"âœ… Your neural network is ready for {recommendation.lower()}!\")\n",
    "print(\"ğŸš€ Next step: Deploy in the web application!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b51fce",
   "metadata": {},
   "source": [
    "# ğŸ“Š Model Evaluation and Performance Analysis\n",
    "\n",
    "**Comprehensive Analysis of Neural Network Performance for Appliance Energy Prediction**\n",
    "\n",
    "This notebook provides in-depth evaluation of our trained neural network model. You'll learn how to assess model performance, identify strengths and weaknesses, and validate the model for real-world deployment.\n",
    "\n",
    "## ğŸ¯ What You'll Learn\n",
    "1. **Load and test** the trained neural network model\n",
    "2. **Comprehensive evaluation** using multiple metrics\n",
    "3. **Cross-validation** for robust performance assessment\n",
    "4. **Feature importance** analysis\n",
    "5. **Model interpretation** and business insights\n",
    "6. **Deployment readiness** assessment\n",
    "\n",
    "## ğŸ“Š Evaluation Approach\n",
    "- **Accuracy Metrics**: RÂ², MSE, MAE, MAPE\n",
    "- **Visual Analysis**: Prediction plots, residual analysis\n",
    "- **Statistical Tests**: Distribution analysis, bias detection\n",
    "- **Business Metrics**: Cost implications, practical accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style and random seeds\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"ğŸ“Š MODEL EVALUATION SETUP COMPLETE!\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ğŸ§  TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"ğŸ“ˆ Ready to evaluate neural network performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e6ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320481d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87352857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6aa181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3260c145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
