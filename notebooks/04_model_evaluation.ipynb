{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1c5571",
   "metadata": {},
   "source": [
    "# üìä Model Evaluation and Performance Analysis\n",
    "\n",
    "**Comprehensive Analysis of Neural Network Performance for Appliance Energy Prediction**\n",
    "\n",
    "This notebook provides in-depth evaluation of our trained neural network model. You'll learn how to assess model performance, identify strengths and weaknesses, and validate the model for real-world deployment.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "1. **Load and test** the trained neural network model\n",
    "2. **Comprehensive evaluation** using multiple metrics\n",
    "3. **Cross-validation** for robust performance assessment\n",
    "4. **Feature importance** analysis\n",
    "5. **Model interpretation** and business insights\n",
    "6. **Deployment readiness** assessment\n",
    "\n",
    "## üìä Evaluation Approach\n",
    "- **Accuracy Metrics**: R¬≤, MSE, MAE, MAPE\n",
    "- **Visual Analysis**: Prediction plots, residual analysis\n",
    "- **Statistical Tests**: Distribution analysis, bias detection\n",
    "- **Business Metrics**: Cost implications, practical accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb718e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style and random seeds\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"üìä MODEL EVALUATION SETUP COMPLETE!\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üß† TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"üìà Ready to evaluate neural network performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740bc93",
   "metadata": {},
   "source": [
    "## 1. üîÑ Loading Trained Model and Data\n",
    "\n",
    "Let's load our trained neural network and prepare the data for comprehensive evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and associated files\n",
    "print(\"üîÑ LOADING TRAINED MODEL AND DATA\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "try:\n",
    "    # Load the trained neural network\n",
    "    model = load_model('../models/appliance_energy_predictor.h5')\n",
    "    print(\"‚úÖ Neural network model loaded successfully!\")\n",
    "    \n",
    "    # Load the feature scaler\n",
    "    scaler = joblib.load('../models/feature_scaler.pkl')\n",
    "    print(\"‚úÖ Feature scaler loaded successfully!\")\n",
    "    \n",
    "    # Load feature names\n",
    "    feature_names = joblib.load('../models/feature_names.pkl')\n",
    "    print(f\"‚úÖ Feature names loaded ({len(feature_names)} features)\")\n",
    "    \n",
    "    # Load model metadata\n",
    "    model_info = joblib.load('../models/model_info.pkl')\n",
    "    print(\"‚úÖ Model metadata loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model files: {e}\")\n",
    "    print(\"üìù Make sure you've run the neural network training notebook first!\")\n",
    "\n",
    "# Load the original dataset\n",
    "print(\"\\nüìÇ Loading original dataset...\")\n",
    "df = pd.read_csv('../data/raw/appliance_data.csv')\n",
    "print(f\"‚úÖ Dataset loaded: {df.shape[0]} records, {df.shape[1]} features\")\n",
    "\n",
    "# Display model information\n",
    "print(\"\\nüß† MODEL INFORMATION:\")\n",
    "print(\"-\" * 25)\n",
    "for key, value in model_info.items():\n",
    "    if key != 'feature_names':\n",
    "        if isinstance(value, float):\n",
    "            print(f\"   üìä {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"   üìã {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for evaluation (same preprocessing as training)\n",
    "print(\"üîß PREPARING DATA FOR EVALUATION\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Feature engineering (same as training)\n",
    "categorical_cols = ['appliance_type', 'location', 'income_level', 'season', 'usage_pattern']\n",
    "numerical_cols = ['power_rating_watts', 'usage_hours_per_day', 'efficiency_rating', \n",
    "                 'appliance_age_years', 'household_size']\n",
    "\n",
    "# Encode categorical variables\n",
    "df_encoded = pd.get_dummies(df[categorical_cols], prefix=categorical_cols)\n",
    "X_features = pd.concat([df[numerical_cols], df_encoded], axis=1)\n",
    "y_target = df['daily_consumption_kwh']\n",
    "\n",
    "# Ensure feature consistency with training data\n",
    "X_features = X_features.reindex(columns=feature_names, fill_value=0)\n",
    "\n",
    "print(f\"‚úÖ Features prepared: {X_features.shape}\")\n",
    "print(f\"üéØ Target variable: {len(y_target)} samples\")\n",
    "\n",
    "# Scale features using the same scaler from training\n",
    "X_scaled = scaler.transform(X_features)\n",
    "print(\"‚úÖ Features scaled using training scaler\")\n",
    "\n",
    "# Generate predictions for the entire dataset\n",
    "print(\"\\nü§ñ Generating predictions...\")\n",
    "y_pred_all = model.predict(X_scaled, verbose=0).flatten()\n",
    "print(f\"‚úÖ Predictions generated for {len(y_pred_all)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd98a37",
   "metadata": {},
   "source": [
    "## 2. üìä Comprehensive Performance Metrics\n",
    "\n",
    "Let's calculate and analyze multiple performance metrics to get a complete picture of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca663768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive performance metrics\n",
    "print(\"üìä COMPREHENSIVE PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Basic regression metrics\n",
    "mse = mean_squared_error(y_target, y_pred_all)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_target, y_pred_all)\n",
    "r2 = r2_score(y_target, y_pred_all)\n",
    "mape = mean_absolute_percentage_error(y_target, y_pred_all) * 100\n",
    "\n",
    "# Additional metrics\n",
    "residuals = y_target - y_pred_all\n",
    "mean_residual = np.mean(residuals)\n",
    "std_residual = np.std(residuals)\n",
    "\n",
    "# Percentage of predictions within certain error bounds\n",
    "within_10_percent = np.mean(np.abs(residuals) <= 0.1 * y_target) * 100\n",
    "within_20_percent = np.mean(np.abs(residuals) <= 0.2 * y_target) * 100\n",
    "within_1_kwh = np.mean(np.abs(residuals) <= 1.0) * 100\n",
    "\n",
    "print(\"üéØ ACCURACY METRICS:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"üìà R¬≤ Score: {r2:.4f} ({r2*100:.2f}% variance explained)\")\n",
    "print(f\"üìä Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"üìâ Root Mean Squared Error: {rmse:.4f} kWh\")\n",
    "print(f\"üìã Mean Absolute Error: {mae:.4f} kWh\")\n",
    "print(f\"üìà Mean Absolute Percentage Error: {mape:.2f}%\")\n",
    "\n",
    "print(\"\\nüéØ RESIDUAL ANALYSIS:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"üìä Mean Residual: {mean_residual:.4f} kWh (bias)\")\n",
    "print(f\"üìà Std Residual: {std_residual:.4f} kWh (spread)\")\n",
    "\n",
    "print(\"\\nüéØ PRACTICAL ACCURACY:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"‚úÖ Within 10% error: {within_10_percent:.1f}% of predictions\")\n",
    "print(f\"‚úÖ Within 20% error: {within_20_percent:.1f}% of predictions\")\n",
    "print(f\"‚úÖ Within 1 kWh error: {within_1_kwh:.1f}% of predictions\")\n",
    "\n",
    "# Performance interpretation\n",
    "print(\"\\nüí° PERFORMANCE INTERPRETATION:\")\n",
    "print(\"-\" * 30)\n",
    "if r2 > 0.9:\n",
    "    performance_level = \"üåü Outstanding\"\n",
    "elif r2 > 0.8:\n",
    "    performance_level = \"üî• Excellent\"\n",
    "elif r2 > 0.7:\n",
    "    performance_level = \"‚úÖ Very Good\"\n",
    "elif r2 > 0.6:\n",
    "    performance_level = \"üëç Good\"\n",
    "elif r2 > 0.5:\n",
    "    performance_level = \"‚ö†Ô∏è Fair\"\n",
    "else:\n",
    "    performance_level = \"‚ùå Poor\"\n",
    "\n",
    "print(f\"üèÜ Overall Performance: {performance_level}\")\n",
    "print(f\"üìä Model explains {r2*100:.1f}% of energy consumption variance\")\n",
    "print(f\"üìà Average prediction error: {mae:.2f} kWh/day\")\n",
    "print(f\"üí∞ This translates to ~‚Çπ{mae * 6:.0f}/month error (at ‚Çπ6/kWh)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05ca3e",
   "metadata": {},
   "source": [
    "## 3. üìà Visual Performance Analysis\n",
    "\n",
    "Let's create comprehensive visualizations to understand model performance across different dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance visualization dashboard\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=[\n",
    "        'üéØ Predicted vs Actual', 'üìä Residual Distribution',\n",
    "        'üìà Residuals vs Predicted', '‚ö° Performance by Appliance',\n",
    "        'üå°Ô∏è Performance by Season', 'üí∞ Error Distribution'\n",
    "    ],\n",
    "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    ")\n",
    "\n",
    "# Plot 1: Predicted vs Actual\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_target, y=y_pred_all,\n",
    "        mode='markers',\n",
    "        name='Predictions',\n",
    "        marker=dict(color='blue', size=4, opacity=0.6)\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Perfect prediction line\n",
    "min_val, max_val = y_target.min(), y_target.max()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[min_val, max_val], y=[min_val, max_val],\n",
    "        mode='lines',\n",
    "        name='Perfect Prediction',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Plot 2: Residual Distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=residuals,\n",
    "        nbinsx=30,\n",
    "        name='Residuals',\n",
    "        marker_color='lightblue'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Plot 3: Residuals vs Predicted\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_pred_all, y=residuals,\n",
    "        mode='markers',\n",
    "        name='Residual Pattern',\n",
    "        marker=dict(color='green', size=4, opacity=0.6)\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Zero line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[y_pred_all.min(), y_pred_all.max()], y=[0, 0],\n",
    "        mode='lines',\n",
    "        name='Zero Error',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Plot 4: Performance by Appliance\n",
    "appliance_mae = df.groupby('appliance_type').apply(\n",
    "    lambda x: mean_absolute_error(\n",
    "        x['daily_consumption_kwh'], \n",
    "        y_pred_all[x.index]\n",
    "    )\n",
    ").sort_values()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=appliance_mae.index,\n",
    "        y=appliance_mae.values,\n",
    "        name='MAE by Appliance',\n",
    "        marker_color='orange'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Plot 5: Performance by Season\n",
    "season_mae = df.groupby('season').apply(\n",
    "    lambda x: mean_absolute_error(\n",
    "        x['daily_consumption_kwh'], \n",
    "        y_pred_all[x.index]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=season_mae.index,\n",
    "        y=season_mae.values,\n",
    "        name='MAE by Season',\n",
    "        marker_color='lightcoral'\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Plot 6: Error Distribution by Range\n",
    "error_ranges = ['0-0.5', '0.5-1.0', '1.0-2.0', '2.0+']\n",
    "error_counts = [\n",
    "    np.sum(np.abs(residuals) <= 0.5),\n",
    "    np.sum((np.abs(residuals) > 0.5) & (np.abs(residuals) <= 1.0)),\n",
    "    np.sum((np.abs(residuals) > 1.0) & (np.abs(residuals) <= 2.0)),\n",
    "    np.sum(np.abs(residuals) > 2.0)\n",
    "]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=error_ranges,\n",
    "        y=error_counts,\n",
    "        name='Error Distribution',\n",
    "        marker_color='lightgreen'\n",
    "    ),\n",
    "    row=3, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1200,\n",
    "    showlegend=False,\n",
    "    title_text=\"üìä Comprehensive Model Performance Dashboard\",\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "# Update axes labels\n",
    "fig.update_xaxes(title_text=\"Actual Consumption (kWh)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Predicted Consumption (kWh)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Residuals (kWh)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Predicted Consumption (kWh)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Residuals (kWh)\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Appliance Type\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"MAE (kWh)\", row=2, col=2)\n",
    "fig.update_xaxes(title_text=\"Season\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"MAE (kWh)\", row=3, col=1)\n",
    "fig.update_xaxes(title_text=\"Error Range (kWh)\", row=3, col=2)\n",
    "fig.update_yaxes(title_text=\"Count\", row=3, col=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"üìä VISUAL ANALYSIS INSIGHTS:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"üéØ Best performing appliance: {appliance_mae.index[0]} (MAE: {appliance_mae.iloc[0]:.3f} kWh)\")\n",
    "print(f\"‚ö†Ô∏è Challenging appliance: {appliance_mae.index[-1]} (MAE: {appliance_mae.iloc[-1]:.3f} kWh)\")\n",
    "print(f\"üå°Ô∏è Best season: {season_mae.idxmin()} (MAE: {season_mae.min():.3f} kWh)\")\n",
    "print(f\"üìà Most predictions ({error_counts[0]}/{len(residuals)}) have <0.5 kWh error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d740905",
   "metadata": {},
   "source": [
    "## 4. üíº Business Impact Analysis\n",
    "\n",
    "Let's analyze the practical business implications of our model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f295728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business impact analysis\n",
    "print(\"üíº BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Cost implications\n",
    "electricity_rate = 6.0  # INR per kWh (average Indian rate)\n",
    "days_per_month = 30\n",
    "\n",
    "# Calculate monthly cost errors\n",
    "monthly_cost_errors = np.abs(residuals) * electricity_rate * days_per_month\n",
    "avg_monthly_cost_error = np.mean(monthly_cost_errors)\n",
    "max_monthly_cost_error = np.max(monthly_cost_errors)\n",
    "\n",
    "# Calculate total consumption and costs\n",
    "total_actual_monthly = y_target.sum() * days_per_month\n",
    "total_predicted_monthly = y_pred_all.sum() * days_per_month\n",
    "total_actual_cost = total_actual_monthly * electricity_rate\n",
    "total_predicted_cost = total_predicted_monthly * electricity_rate\n",
    "\n",
    "print(\"üí∞ COST IMPACT ANALYSIS:\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"   üìä Average monthly cost error: ‚Çπ{avg_monthly_cost_error:.2f} per appliance\")\n",
    "print(f\"   üìà Maximum monthly cost error: ‚Çπ{max_monthly_cost_error:.2f} per appliance\")\n",
    "print(f\"   üìã Median monthly cost error: ‚Çπ{np.median(monthly_cost_errors):.2f} per appliance\")\n",
    "\n",
    "# Error by appliance type\n",
    "print(\"\\n‚ö° ERROR BY APPLIANCE TYPE:\")\n",
    "print(\"-\" * 30)\n",
    "for appliance in df['appliance_type'].unique():\n",
    "    mask = df['appliance_type'] == appliance\n",
    "    appliance_errors = monthly_cost_errors[mask]\n",
    "    avg_error = np.mean(appliance_errors)\n",
    "    print(f\"   üìä {appliance}: ‚Çπ{avg_error:.2f}/month average error\")\n",
    "\n",
    "# Model reliability assessment\n",
    "print(\"\\nüõ°Ô∏è MODEL RELIABILITY ASSESSMENT:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "reliable_predictions = np.sum(np.abs(residuals) <= 0.5) / len(residuals) * 100\n",
    "acceptable_predictions = np.sum(np.abs(residuals) <= 1.0) / len(residuals) * 100\n",
    "\n",
    "print(f\"   ‚úÖ Highly reliable predictions (‚â§0.5 kWh error): {reliable_predictions:.1f}%\")\n",
    "print(f\"   üëç Acceptable predictions (‚â§1.0 kWh error): {acceptable_predictions:.1f}%\")\n",
    "\n",
    "# Business recommendations\n",
    "print(\"\\nüìã BUSINESS RECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "if reliable_predictions > 70:\n",
    "    print(\"   üåü Excellent reliability - ready for production deployment\")\n",
    "    print(\"   ‚úÖ Can be used for energy planning and cost estimation\")\n",
    "elif reliable_predictions > 50:\n",
    "    print(\"   üëç Good reliability - suitable for most applications\")\n",
    "    print(\"   ‚ö†Ô∏è Consider confidence intervals for critical decisions\")\n",
    "else:\n",
    "    print(\"   ‚ùå Limited reliability - needs improvement before deployment\")\n",
    "    print(\"   üîß Consider collecting more data or feature engineering\")\n",
    "\n",
    "print(f\"\\nüí° For household energy management, this model can save families\")\n",
    "print(f\"   an average of ‚Çπ{avg_monthly_cost_error:.0f}/month in prediction accuracy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba26ff7",
   "metadata": {},
   "source": [
    "## 5. üìù Model Evaluation Summary and Recommendations\n",
    "\n",
    "Let's create a comprehensive summary of our model evaluation findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive evaluation summary\n",
    "print(\"üìù COMPREHENSIVE MODEL EVALUATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Executive Summary\n",
    "print(\"üéØ EXECUTIVE SUMMARY:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"   üß† Model Type: Neural Network (TensorFlow/Keras)\")\n",
    "print(f\"   üìä Dataset Size: {len(df):,} appliances from {df['household_id'].nunique()} households\")\n",
    "print(f\"   üéØ Target Variable: Daily Energy Consumption (kWh)\")\n",
    "print(f\"   üìà Overall Performance: {performance_level}\")\n",
    "print(f\"   üìä Accuracy (R¬≤): {r2:.3f} ({r2*100:.1f}% variance explained)\")\n",
    "print(f\"   üí∞ Average Cost Error: ‚Çπ{avg_monthly_cost_error:.2f}/month per appliance\")\n",
    "\n",
    "# Strengths\n",
    "print(\"\\nüí™ MODEL STRENGTHS:\")\n",
    "print(\"-\" * 20)\n",
    "strengths = []\n",
    "if r2 > 0.7:\n",
    "    strengths.append(\"High predictive accuracy\")\n",
    "if within_20_percent > 80:\n",
    "    strengths.append(\"Most predictions within 20% error\")\n",
    "if abs(mean_residual) < 0.1:\n",
    "    strengths.append(\"Low systematic bias\")\n",
    "\n",
    "for i, strength in enumerate(strengths, 1):\n",
    "    print(f\"   {i}. ‚úÖ {strength}\")\n",
    "\n",
    "# Deployment Readiness\n",
    "print(\"\\nüöÄ DEPLOYMENT READINESS:\")\n",
    "print(\"-\" * 25)\n",
    "deployment_score = 0\n",
    "max_score = 5\n",
    "\n",
    "# Scoring criteria\n",
    "if r2 > 0.7: deployment_score += 1\n",
    "if within_20_percent > 75: deployment_score += 1\n",
    "if abs(mean_residual) < 0.2: deployment_score += 1\n",
    "if avg_monthly_cost_error < 100: deployment_score += 1\n",
    "if reliable_predictions > 60: deployment_score += 1\n",
    "\n",
    "deployment_percentage = (deployment_score / max_score) * 100\n",
    "\n",
    "print(f\"   üìä Deployment Score: {deployment_score}/{max_score} ({deployment_percentage:.0f}%)\")\n",
    "\n",
    "if deployment_percentage >= 80:\n",
    "    readiness = \"üü¢ Ready for Production\"\n",
    "    recommendation = \"Deploy with confidence\"\n",
    "elif deployment_percentage >= 60:\n",
    "    readiness = \"üü° Ready with Monitoring\"\n",
    "    recommendation = \"Deploy with careful monitoring\"\n",
    "else:\n",
    "    readiness = \"üî¥ Needs Improvement\"\n",
    "    recommendation = \"Improve before deployment\"\n",
    "\n",
    "print(f\"   üéØ Status: {readiness}\")\n",
    "print(f\"   üí° Recommendation: {recommendation}\")\n",
    "\n",
    "# Final Recommendations\n",
    "print(\"\\nüìã FINAL RECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"   1. üì± Integrate model into web application for user predictions\")\n",
    "print(\"   2. üîÑ Implement model monitoring and performance tracking\")\n",
    "print(\"   3. üìä Collect user feedback to improve future versions\")\n",
    "print(\"   4. ‚öñÔ∏è Add confidence intervals for critical business decisions\")\n",
    "print(\"   5. üîß Consider ensemble methods for improved robustness\")\n",
    "\n",
    "# Save evaluation results\n",
    "evaluation_results = {\n",
    "    'r2_score': r2,\n",
    "    'mae': mae,\n",
    "    'rmse': rmse,\n",
    "    'mape': mape,\n",
    "    'within_20_percent': within_20_percent,\n",
    "    'avg_monthly_cost_error': avg_monthly_cost_error,\n",
    "    'deployment_score': deployment_score,\n",
    "    'deployment_percentage': deployment_percentage,\n",
    "    'best_appliance': appliance_mae.index[0],\n",
    "    'worst_appliance': appliance_mae.index[-1]\n",
    "}\n",
    "\n",
    "joblib.dump(evaluation_results, '../models/evaluation_results.pkl')\n",
    "print(\"\\nüíæ Evaluation results saved for future reference!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéâ MODEL EVALUATION COMPLETE!\")\n",
    "print(f\"‚úÖ Your neural network is ready for {recommendation.lower()}!\")\n",
    "print(\"üöÄ Next step: Deploy in the web application!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b51fce",
   "metadata": {},
   "source": [
    "# üìä Model Evaluation and Performance Analysis\n",
    "\n",
    "**Comprehensive Analysis of Neural Network Performance for Appliance Energy Prediction**\n",
    "\n",
    "This notebook provides in-depth evaluation of our trained neural network model. You'll learn how to assess model performance, identify strengths and weaknesses, and validate the model for real-world deployment.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "1. **Load and test** the trained neural network model\n",
    "2. **Comprehensive evaluation** using multiple metrics\n",
    "3. **Cross-validation** for robust performance assessment\n",
    "4. **Feature importance** analysis\n",
    "5. **Model interpretation** and business insights\n",
    "6. **Deployment readiness** assessment\n",
    "\n",
    "## üìä Evaluation Approach\n",
    "- **Accuracy Metrics**: R¬≤, MSE, MAE, MAPE\n",
    "- **Visual Analysis**: Prediction plots, residual analysis\n",
    "- **Statistical Tests**: Distribution analysis, bias detection\n",
    "- **Business Metrics**: Cost implications, practical accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style and random seeds\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"üìä MODEL EVALUATION SETUP COMPLETE!\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üß† TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"üìà Ready to evaluate neural network performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e6ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320481d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87352857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6aa181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3260c145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
