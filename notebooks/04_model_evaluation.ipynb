{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1c5571",
   "metadata": {},
   "source": [
    "# 📊 Model Evaluation and Performance Analysis\n",
    "\n",
    "**Comprehensive Analysis of Neural Network Performance for Appliance Energy Prediction**\n",
    "\n",
    "This notebook provides in-depth evaluation of our trained neural network model. You'll learn how to assess model performance, identify strengths and weaknesses, and validate the model for real-world deployment.\n",
    "\n",
    "## 🎯 What You'll Learn\n",
    "1. **Load and test** the trained neural network model\n",
    "2. **Comprehensive evaluation** using multiple metrics\n",
    "3. **Cross-validation** for robust performance assessment\n",
    "4. **Feature importance** analysis\n",
    "5. **Model interpretation** and business insights\n",
    "6. **Deployment readiness** assessment\n",
    "\n",
    "## 📊 Evaluation Approach\n",
    "- **Accuracy Metrics**: R², MSE, MAE, MAPE\n",
    "- **Visual Analysis**: Prediction plots, residual analysis\n",
    "- **Statistical Tests**: Distribution analysis, bias detection\n",
    "- **Business Metrics**: Cost implications, practical accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb718e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style and random seeds\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"📊 MODEL EVALUATION SETUP COMPLETE!\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"🧠 TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"📈 Ready to evaluate neural network performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740bc93",
   "metadata": {},
   "source": [
    "## 1. 🔄 Loading Trained Model and Data\n",
    "\n",
    "Let's load our trained neural network and prepare the data for comprehensive evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and associated files\n",
    "print(\"🔄 LOADING TRAINED MODEL AND DATA\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "try:\n",
    "    # Load the trained neural network\n",
    "    model = load_model('../models/appliance_energy_predictor.h5')\n",
    "    print(\"✅ Neural network model loaded successfully!\")\n",
    "    \n",
    "    # Load the feature scaler\n",
    "    scaler = joblib.load('../models/feature_scaler.pkl')\n",
    "    print(\"✅ Feature scaler loaded successfully!\")\n",
    "    \n",
    "    # Load feature names\n",
    "    feature_names = joblib.load('../models/feature_names.pkl')\n",
    "    print(f\"✅ Feature names loaded ({len(feature_names)} features)\")\n",
    "    \n",
    "    # Load model metadata\n",
    "    model_info = joblib.load('../models/model_info.pkl')\n",
    "    print(\"✅ Model metadata loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading model files: {e}\")\n",
    "    print(\"📝 Make sure you've run the neural network training notebook first!\")\n",
    "\n",
    "# Load the original dataset\n",
    "print(\"\\n📂 Loading original dataset...\")\n",
    "df = pd.read_csv('../data/raw/appliance_data.csv')\n",
    "print(f\"✅ Dataset loaded: {df.shape[0]} records, {df.shape[1]} features\")\n",
    "\n",
    "# Display model information\n",
    "print(\"\\n🧠 MODEL INFORMATION:\")\n",
    "print(\"-\" * 25)\n",
    "for key, value in model_info.items():\n",
    "    if key != 'feature_names':\n",
    "        if isinstance(value, float):\n",
    "            print(f\"   📊 {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"   📋 {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for evaluation (same preprocessing as training)\n",
    "print(\"🔧 PREPARING DATA FOR EVALUATION\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Feature engineering (same as training)\n",
    "categorical_cols = ['appliance_type', 'location', 'income_level', 'season', 'usage_pattern']\n",
    "numerical_cols = ['power_rating_watts', 'usage_hours_per_day', 'efficiency_rating', \n",
    "                 'appliance_age_years', 'household_size']\n",
    "\n",
    "# Encode categorical variables\n",
    "df_encoded = pd.get_dummies(df[categorical_cols], prefix=categorical_cols)\n",
    "X_features = pd.concat([df[numerical_cols], df_encoded], axis=1)\n",
    "y_target = df['daily_consumption_kwh']\n",
    "\n",
    "# Ensure feature consistency with training data\n",
    "X_features = X_features.reindex(columns=feature_names, fill_value=0)\n",
    "\n",
    "print(f\"✅ Features prepared: {X_features.shape}\")\n",
    "print(f\"🎯 Target variable: {len(y_target)} samples\")\n",
    "\n",
    "# Scale features using the same scaler from training\n",
    "X_scaled = scaler.transform(X_features)\n",
    "print(\"✅ Features scaled using training scaler\")\n",
    "\n",
    "# Generate predictions for the entire dataset\n",
    "print(\"\\n🤖 Generating predictions...\")\n",
    "y_pred_all = model.predict(X_scaled, verbose=0).flatten()\n",
    "print(f\"✅ Predictions generated for {len(y_pred_all)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd98a37",
   "metadata": {},
   "source": [
    "## 2. 📊 Comprehensive Performance Metrics\n",
    "\n",
    "Let's calculate and analyze multiple performance metrics to get a complete picture of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca663768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive performance metrics\n",
    "print(\"📊 COMPREHENSIVE PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Basic regression metrics\n",
    "mse = mean_squared_error(y_target, y_pred_all)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_target, y_pred_all)\n",
    "r2 = r2_score(y_target, y_pred_all)\n",
    "mape = mean_absolute_percentage_error(y_target, y_pred_all) * 100\n",
    "\n",
    "# Additional metrics\n",
    "residuals = y_target - y_pred_all\n",
    "mean_residual = np.mean(residuals)\n",
    "std_residual = np.std(residuals)\n",
    "\n",
    "# Percentage of predictions within certain error bounds\n",
    "within_10_percent = np.mean(np.abs(residuals) <= 0.1 * y_target) * 100\n",
    "within_20_percent = np.mean(np.abs(residuals) <= 0.2 * y_target) * 100\n",
    "within_1_kwh = np.mean(np.abs(residuals) <= 1.0) * 100\n",
    "\n",
    "print(\"🎯 ACCURACY METRICS:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"📈 R² Score: {r2:.4f} ({r2*100:.2f}% variance explained)\")\n",
    "print(f\"📊 Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"📉 Root Mean Squared Error: {rmse:.4f} kWh\")\n",
    "print(f\"📋 Mean Absolute Error: {mae:.4f} kWh\")\n",
    "print(f\"📈 Mean Absolute Percentage Error: {mape:.2f}%\")\n",
    "\n",
    "print(\"\\n🎯 RESIDUAL ANALYSIS:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"📊 Mean Residual: {mean_residual:.4f} kWh (bias)\")\n",
    "print(f\"📈 Std Residual: {std_residual:.4f} kWh (spread)\")\n",
    "\n",
    "print(\"\\n🎯 PRACTICAL ACCURACY:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"✅ Within 10% error: {within_10_percent:.1f}% of predictions\")\n",
    "print(f\"✅ Within 20% error: {within_20_percent:.1f}% of predictions\")\n",
    "print(f\"✅ Within 1 kWh error: {within_1_kwh:.1f}% of predictions\")\n",
    "\n",
    "# Performance interpretation\n",
    "print(\"\\n💡 PERFORMANCE INTERPRETATION:\")\n",
    "print(\"-\" * 30)\n",
    "if r2 > 0.9:\n",
    "    performance_level = \"🌟 Outstanding\"\n",
    "elif r2 > 0.8:\n",
    "    performance_level = \"🔥 Excellent\"\n",
    "elif r2 > 0.7:\n",
    "    performance_level = \"✅ Very Good\"\n",
    "elif r2 > 0.6:\n",
    "    performance_level = \"👍 Good\"\n",
    "elif r2 > 0.5:\n",
    "    performance_level = \"⚠️ Fair\"\n",
    "else:\n",
    "    performance_level = \"❌ Poor\"\n",
    "\n",
    "print(f\"🏆 Overall Performance: {performance_level}\")\n",
    "print(f\"📊 Model explains {r2*100:.1f}% of energy consumption variance\")\n",
    "print(f\"📈 Average prediction error: {mae:.2f} kWh/day\")\n",
    "print(f\"💰 This translates to ~₹{mae * 6:.0f}/month error (at ₹6/kWh)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05ca3e",
   "metadata": {},
   "source": [
    "## 3. 📈 Visual Performance Analysis\n",
    "\n",
    "Let's create comprehensive visualizations to understand model performance across different dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance visualization dashboard\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=[\n",
    "        '🎯 Predicted vs Actual', '📊 Residual Distribution',\n",
    "        '📈 Residuals vs Predicted', '⚡ Performance by Appliance',\n",
    "        '🌡️ Performance by Season', '💰 Error Distribution'\n",
    "    ],\n",
    "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    ")\n",
    "\n",
    "# Plot 1: Predicted vs Actual\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_target, y=y_pred_all,\n",
    "        mode='markers',\n",
    "        name='Predictions',\n",
    "        marker=dict(color='blue', size=4, opacity=0.6)\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Perfect prediction line\n",
    "min_val, max_val = y_target.min(), y_target.max()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[min_val, max_val], y=[min_val, max_val],\n",
    "        mode='lines',\n",
    "        name='Perfect Prediction',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Plot 2: Residual Distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=residuals,\n",
    "        nbinsx=30,\n",
    "        name='Residuals',\n",
    "        marker_color='lightblue'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Plot 3: Residuals vs Predicted\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_pred_all, y=residuals,\n",
    "        mode='markers',\n",
    "        name='Residual Pattern',\n",
    "        marker=dict(color='green', size=4, opacity=0.6)\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Zero line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[y_pred_all.min(), y_pred_all.max()], y=[0, 0],\n",
    "        mode='lines',\n",
    "        name='Zero Error',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Plot 4: Performance by Appliance\n",
    "appliance_mae = df.groupby('appliance_type').apply(\n",
    "    lambda x: mean_absolute_error(\n",
    "        x['daily_consumption_kwh'], \n",
    "        y_pred_all[x.index]\n",
    "    )\n",
    ").sort_values()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=appliance_mae.index,\n",
    "        y=appliance_mae.values,\n",
    "        name='MAE by Appliance',\n",
    "        marker_color='orange'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Plot 5: Performance by Season\n",
    "season_mae = df.groupby('season').apply(\n",
    "    lambda x: mean_absolute_error(\n",
    "        x['daily_consumption_kwh'], \n",
    "        y_pred_all[x.index]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=season_mae.index,\n",
    "        y=season_mae.values,\n",
    "        name='MAE by Season',\n",
    "        marker_color='lightcoral'\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Plot 6: Error Distribution by Range\n",
    "error_ranges = ['0-0.5', '0.5-1.0', '1.0-2.0', '2.0+']\n",
    "error_counts = [\n",
    "    np.sum(np.abs(residuals) <= 0.5),\n",
    "    np.sum((np.abs(residuals) > 0.5) & (np.abs(residuals) <= 1.0)),\n",
    "    np.sum((np.abs(residuals) > 1.0) & (np.abs(residuals) <= 2.0)),\n",
    "    np.sum(np.abs(residuals) > 2.0)\n",
    "]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=error_ranges,\n",
    "        y=error_counts,\n",
    "        name='Error Distribution',\n",
    "        marker_color='lightgreen'\n",
    "    ),\n",
    "    row=3, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1200,\n",
    "    showlegend=False,\n",
    "    title_text=\"📊 Comprehensive Model Performance Dashboard\",\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "# Update axes labels\n",
    "fig.update_xaxes(title_text=\"Actual Consumption (kWh)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Predicted Consumption (kWh)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Residuals (kWh)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Predicted Consumption (kWh)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Residuals (kWh)\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Appliance Type\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"MAE (kWh)\", row=2, col=2)\n",
    "fig.update_xaxes(title_text=\"Season\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"MAE (kWh)\", row=3, col=1)\n",
    "fig.update_xaxes(title_text=\"Error Range (kWh)\", row=3, col=2)\n",
    "fig.update_yaxes(title_text=\"Count\", row=3, col=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"📊 VISUAL ANALYSIS INSIGHTS:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"🎯 Best performing appliance: {appliance_mae.index[0]} (MAE: {appliance_mae.iloc[0]:.3f} kWh)\")\n",
    "print(f\"⚠️ Challenging appliance: {appliance_mae.index[-1]} (MAE: {appliance_mae.iloc[-1]:.3f} kWh)\")\n",
    "print(f\"🌡️ Best season: {season_mae.idxmin()} (MAE: {season_mae.min():.3f} kWh)\")\n",
    "print(f\"📈 Most predictions ({error_counts[0]}/{len(residuals)}) have <0.5 kWh error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d740905",
   "metadata": {},
   "source": [
    "## 4. 💼 Business Impact Analysis\n",
    "\n",
    "Let's analyze the practical business implications of our model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f295728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business impact analysis\n",
    "print(\"💼 BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Cost implications\n",
    "electricity_rate = 6.0  # INR per kWh (average Indian rate)\n",
    "days_per_month = 30\n",
    "\n",
    "# Calculate monthly cost errors\n",
    "monthly_cost_errors = np.abs(residuals) * electricity_rate * days_per_month\n",
    "avg_monthly_cost_error = np.mean(monthly_cost_errors)\n",
    "max_monthly_cost_error = np.max(monthly_cost_errors)\n",
    "\n",
    "# Calculate total consumption and costs\n",
    "total_actual_monthly = y_target.sum() * days_per_month\n",
    "total_predicted_monthly = y_pred_all.sum() * days_per_month\n",
    "total_actual_cost = total_actual_monthly * electricity_rate\n",
    "total_predicted_cost = total_predicted_monthly * electricity_rate\n",
    "\n",
    "print(\"💰 COST IMPACT ANALYSIS:\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"   📊 Average monthly cost error: ₹{avg_monthly_cost_error:.2f} per appliance\")\n",
    "print(f\"   📈 Maximum monthly cost error: ₹{max_monthly_cost_error:.2f} per appliance\")\n",
    "print(f\"   📋 Median monthly cost error: ₹{np.median(monthly_cost_errors):.2f} per appliance\")\n",
    "\n",
    "# Error by appliance type\n",
    "print(\"\\n⚡ ERROR BY APPLIANCE TYPE:\")\n",
    "print(\"-\" * 30)\n",
    "for appliance in df['appliance_type'].unique():\n",
    "    mask = df['appliance_type'] == appliance\n",
    "    appliance_errors = monthly_cost_errors[mask]\n",
    "    avg_error = np.mean(appliance_errors)\n",
    "    print(f\"   📊 {appliance}: ₹{avg_error:.2f}/month average error\")\n",
    "\n",
    "# Model reliability assessment\n",
    "print(\"\\n🛡️ MODEL RELIABILITY ASSESSMENT:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "reliable_predictions = np.sum(np.abs(residuals) <= 0.5) / len(residuals) * 100\n",
    "acceptable_predictions = np.sum(np.abs(residuals) <= 1.0) / len(residuals) * 100\n",
    "\n",
    "print(f\"   ✅ Highly reliable predictions (≤0.5 kWh error): {reliable_predictions:.1f}%\")\n",
    "print(f\"   👍 Acceptable predictions (≤1.0 kWh error): {acceptable_predictions:.1f}%\")\n",
    "\n",
    "# Business recommendations\n",
    "print(\"\\n📋 BUSINESS RECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "if reliable_predictions > 70:\n",
    "    print(\"   🌟 Excellent reliability - ready for production deployment\")\n",
    "    print(\"   ✅ Can be used for energy planning and cost estimation\")\n",
    "elif reliable_predictions > 50:\n",
    "    print(\"   👍 Good reliability - suitable for most applications\")\n",
    "    print(\"   ⚠️ Consider confidence intervals for critical decisions\")\n",
    "else:\n",
    "    print(\"   ❌ Limited reliability - needs improvement before deployment\")\n",
    "    print(\"   🔧 Consider collecting more data or feature engineering\")\n",
    "\n",
    "print(f\"\\n💡 For household energy management, this model can save families\")\n",
    "print(f\"   an average of ₹{avg_monthly_cost_error:.0f}/month in prediction accuracy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba26ff7",
   "metadata": {},
   "source": [
    "## 5. 📝 Model Evaluation Summary and Recommendations\n",
    "\n",
    "Let's create a comprehensive summary of our model evaluation findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive evaluation summary\n",
    "print(\"📝 COMPREHENSIVE MODEL EVALUATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Executive Summary\n",
    "print(\"🎯 EXECUTIVE SUMMARY:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"   🧠 Model Type: Neural Network (TensorFlow/Keras)\")\n",
    "print(f\"   📊 Dataset Size: {len(df):,} appliances from {df['household_id'].nunique()} households\")\n",
    "print(f\"   🎯 Target Variable: Daily Energy Consumption (kWh)\")\n",
    "print(f\"   📈 Overall Performance: {performance_level}\")\n",
    "print(f\"   📊 Accuracy (R²): {r2:.3f} ({r2*100:.1f}% variance explained)\")\n",
    "print(f\"   💰 Average Cost Error: ₹{avg_monthly_cost_error:.2f}/month per appliance\")\n",
    "\n",
    "# Strengths\n",
    "print(\"\\n💪 MODEL STRENGTHS:\")\n",
    "print(\"-\" * 20)\n",
    "strengths = []\n",
    "if r2 > 0.7:\n",
    "    strengths.append(\"High predictive accuracy\")\n",
    "if within_20_percent > 80:\n",
    "    strengths.append(\"Most predictions within 20% error\")\n",
    "if abs(mean_residual) < 0.1:\n",
    "    strengths.append(\"Low systematic bias\")\n",
    "\n",
    "for i, strength in enumerate(strengths, 1):\n",
    "    print(f\"   {i}. ✅ {strength}\")\n",
    "\n",
    "# Deployment Readiness\n",
    "print(\"\\n🚀 DEPLOYMENT READINESS:\")\n",
    "print(\"-\" * 25)\n",
    "deployment_score = 0\n",
    "max_score = 5\n",
    "\n",
    "# Scoring criteria\n",
    "if r2 > 0.7: deployment_score += 1\n",
    "if within_20_percent > 75: deployment_score += 1\n",
    "if abs(mean_residual) < 0.2: deployment_score += 1\n",
    "if avg_monthly_cost_error < 100: deployment_score += 1\n",
    "if reliable_predictions > 60: deployment_score += 1\n",
    "\n",
    "deployment_percentage = (deployment_score / max_score) * 100\n",
    "\n",
    "print(f\"   📊 Deployment Score: {deployment_score}/{max_score} ({deployment_percentage:.0f}%)\")\n",
    "\n",
    "if deployment_percentage >= 80:\n",
    "    readiness = \"🟢 Ready for Production\"\n",
    "    recommendation = \"Deploy with confidence\"\n",
    "elif deployment_percentage >= 60:\n",
    "    readiness = \"🟡 Ready with Monitoring\"\n",
    "    recommendation = \"Deploy with careful monitoring\"\n",
    "else:\n",
    "    readiness = \"🔴 Needs Improvement\"\n",
    "    recommendation = \"Improve before deployment\"\n",
    "\n",
    "print(f\"   🎯 Status: {readiness}\")\n",
    "print(f\"   💡 Recommendation: {recommendation}\")\n",
    "\n",
    "# Final Recommendations\n",
    "print(\"\\n📋 FINAL RECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"   1. 📱 Integrate model into web application for user predictions\")\n",
    "print(\"   2. 🔄 Implement model monitoring and performance tracking\")\n",
    "print(\"   3. 📊 Collect user feedback to improve future versions\")\n",
    "print(\"   4. ⚖️ Add confidence intervals for critical business decisions\")\n",
    "print(\"   5. 🔧 Consider ensemble methods for improved robustness\")\n",
    "\n",
    "# Save evaluation results\n",
    "evaluation_results = {\n",
    "    'r2_score': r2,\n",
    "    'mae': mae,\n",
    "    'rmse': rmse,\n",
    "    'mape': mape,\n",
    "    'within_20_percent': within_20_percent,\n",
    "    'avg_monthly_cost_error': avg_monthly_cost_error,\n",
    "    'deployment_score': deployment_score,\n",
    "    'deployment_percentage': deployment_percentage,\n",
    "    'best_appliance': appliance_mae.index[0],\n",
    "    'worst_appliance': appliance_mae.index[-1]\n",
    "}\n",
    "\n",
    "joblib.dump(evaluation_results, '../models/evaluation_results.pkl')\n",
    "print(\"\\n💾 Evaluation results saved for future reference!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🎉 MODEL EVALUATION COMPLETE!\")\n",
    "print(f\"✅ Your neural network is ready for {recommendation.lower()}!\")\n",
    "print(\"🚀 Next step: Deploy in the web application!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b51fce",
   "metadata": {},
   "source": [
    "# 📊 Model Evaluation and Performance Analysis\n",
    "\n",
    "**Comprehensive Analysis of Neural Network Performance for Appliance Energy Prediction**\n",
    "\n",
    "This notebook provides in-depth evaluation of our trained neural network model. You'll learn how to assess model performance, identify strengths and weaknesses, and validate the model for real-world deployment.\n",
    "\n",
    "## 🎯 What You'll Learn\n",
    "1. **Load and test** the trained neural network model\n",
    "2. **Comprehensive evaluation** using multiple metrics\n",
    "3. **Cross-validation** for robust performance assessment\n",
    "4. **Feature importance** analysis\n",
    "5. **Model interpretation** and business insights\n",
    "6. **Deployment readiness** assessment\n",
    "\n",
    "## 📊 Evaluation Approach\n",
    "- **Accuracy Metrics**: R², MSE, MAE, MAPE\n",
    "- **Visual Analysis**: Prediction plots, residual analysis\n",
    "- **Statistical Tests**: Distribution analysis, bias detection\n",
    "- **Business Metrics**: Cost implications, practical accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style and random seeds\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"📊 MODEL EVALUATION SETUP COMPLETE!\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"🧠 TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"📈 Ready to evaluate neural network performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e6ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320481d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87352857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6aa181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3260c145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
