{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1c5571",
   "metadata": {},
   "source": [
    "# üìä Model Evaluation and Performance Analysis\n",
    "\n",
    "**Comprehensive Analysis of Neural Network Performance for Appliance Energy Prediction**\n",
    "\n",
    "This notebook provides in-depth evaluation of our trained neural network model. You'll learn how to assess model performance, identify strengths and weaknesses, and validate the model for real-world deployment.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "1. **Load and test** the trained neural network model\n",
    "2. **Comprehensive evaluation** using multiple metrics\n",
    "3. **Cross-validation** for robust performance assessment\n",
    "4. **Feature importance** analysis\n",
    "5. **Model interpretation** and business insights\n",
    "6. **Deployment readiness** assessment\n",
    "\n",
    "## üìä Evaluation Approach\n",
    "- **Accuracy Metrics**: R¬≤, MSE, MAE, MAPE\n",
    "- **Visual Analysis**: Prediction plots, residual analysis\n",
    "- **Statistical Tests**: Distribution analysis, bias detection\n",
    "- **Business Metrics**: Cost implications, practical accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb718e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for neural network evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Machine learning evaluation libraries\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro, pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"\ude80 NEURAL NETWORK MODEL EVALUATION SETUP\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"üìä TensorFlow: {tf.__version__}\")\n",
    "print(f\"üî¢ NumPy: {np.__version__}\")\n",
    "print(f\"üìà Pandas: {pd.__version__}\")\n",
    "print(f\"\udcca Matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"üé® Seaborn: {sns.__version__}\")\n",
    "print(\"üß† Ready for comprehensive neural network evaluation!\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740bc93",
   "metadata": {},
   "source": [
    "## 1. üîÑ Loading Trained Model and Data\n",
    "\n",
    "Let's load our trained neural network and prepare the data for comprehensive evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained neural network model and data\n",
    "print(\"\udcc2 LOADING TRAINED MODEL & DATA\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Define paths\n",
    "models_dir = Path('../models')\n",
    "processed_dir = Path('../data/processed')\n",
    "\n",
    "# Load the trained neural network model\n",
    "model_path = models_dir / 'appliance_energy_model.h5'\n",
    "\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "    print(f\"‚úÖ Neural network model loaded successfully\")\n",
    "    print(f\"üìÅ Model path: {model_path}\")\n",
    "    \n",
    "    # Display model architecture summary\n",
    "    print(f\"\\nüß† Model Architecture:\")\n",
    "    print(f\"   üìä Total parameters: {model.count_params():,}\")\n",
    "    print(f\"   üèóÔ∏è  Layers: {len(model.layers)}\")\n",
    "    print(f\"   üì• Input shape: {model.input_shape}\")\n",
    "    print(f\"   üì§ Output shape: {model.output_shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    print(\"üìù Please run the neural network training notebook first!\")\n",
    "    raise\n",
    "\n",
    "# Load model metadata\n",
    "try:\n",
    "    with open(models_dir / 'model_metadata.json', 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    print(f\"‚úÖ Model metadata loaded\")\n",
    "    \n",
    "    print(f\"\\n\udccb Training Information:\")\n",
    "    print(f\"   üìÖ Training date: {metadata['training_date']}\")\n",
    "    print(f\"   ‚è±Ô∏è  Training duration: {metadata['training_duration']}\")\n",
    "    print(f\"   üîÑ Epochs trained: {metadata['epochs_trained']}\")\n",
    "    print(f\"   üì¶ Batch size: {metadata['batch_size']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Metadata not found: {e}\")\n",
    "    metadata = {}\n",
    "\n",
    "# Load test data\n",
    "try:\n",
    "    X_test = pd.read_csv(processed_dir / 'X_test_scaled.csv')\n",
    "    y_test = pd.read_csv(processed_dir / 'y_test.csv').values.ravel()\n",
    "    \n",
    "    # Also load train and validation for comprehensive analysis\n",
    "    X_train = pd.read_csv(processed_dir / 'X_train_scaled.csv')\n",
    "    y_train = pd.read_csv(processed_dir / 'y_train.csv').values.ravel()\n",
    "    X_val = pd.read_csv(processed_dir / 'X_val_scaled.csv')\n",
    "    y_val = pd.read_csv(processed_dir / 'y_val.csv').values.ravel()\n",
    "    \n",
    "    print(f\"‚úÖ Test data loaded successfully\")\n",
    "    print(f\"üìä Test set shape: {X_test.shape}\")\n",
    "    print(f\"üéØ Test target range: {y_test.min():.1f} - {y_test.max():.1f} kWh/month\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading test data: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\nüéØ Ready for comprehensive model evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for comprehensive evaluation\n",
    "print(\"\udd2e GENERATING PREDICTIONS FOR EVALUATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Generate predictions on all datasets\n",
    "print(\"üéØ Making predictions on all datasets...\")\n",
    "\n",
    "y_train_pred = model.predict(X_train, verbose=0).flatten()\n",
    "y_val_pred = model.predict(X_val, verbose=0).flatten() \n",
    "y_test_pred = model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "print(f\"‚úÖ Predictions generated:\")\n",
    "print(f\"   üèãÔ∏è Training predictions: {len(y_train_pred)}\")\n",
    "print(f\"   ‚úÖ Validation predictions: {len(y_val_pred)}\")\n",
    "print(f\"   üß™ Test predictions: {len(y_test_pred)}\")\n",
    "\n",
    "# Quick prediction statistics\n",
    "print(f\"\\nüìä Prediction Statistics:\")\n",
    "for name, y_true, y_pred in [('Train', y_train, y_train_pred), \n",
    "                            ('Val', y_val, y_val_pred), \n",
    "                            ('Test', y_test, y_test_pred)]:\n",
    "    print(f\"   {name} - Actual: {y_true.min():.1f}-{y_true.max():.1f}, Predicted: {y_pred.min():.1f}-{y_pred.max():.1f}\")\n",
    "\n",
    "# Check for any prediction anomalies\n",
    "def check_prediction_anomalies(y_pred, dataset_name):\n",
    "    \"\"\"Check for common prediction issues\"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    # Check for NaN or infinite values\n",
    "    if np.isnan(y_pred).any():\n",
    "        issues.append(\"Contains NaN values\")\n",
    "    if np.isinf(y_pred).any():\n",
    "        issues.append(\"Contains infinite values\")\n",
    "        \n",
    "    # Check for negative predictions (energy consumption should be positive)\n",
    "    negative_count = (y_pred < 0).sum()\n",
    "    if negative_count > 0:\n",
    "        issues.append(f\"{negative_count} negative predictions\")\n",
    "        \n",
    "    # Check for unrealistic high values\n",
    "    high_threshold = 1000  # 1000 kWh/month seems unreasonably high\n",
    "    high_count = (y_pred > high_threshold).sum()\n",
    "    if high_count > 0:\n",
    "        issues.append(f\"{high_count} unusually high predictions (>{high_threshold} kWh)\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"‚ö†Ô∏è  {dataset_name} prediction issues: {', '.join(issues)}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ {dataset_name} predictions: No anomalies detected\")\n",
    "\n",
    "# Check all datasets for anomalies\n",
    "check_prediction_anomalies(y_train_pred, \"Training\")\n",
    "check_prediction_anomalies(y_val_pred, \"Validation\")\n",
    "check_prediction_anomalies(y_test_pred, \"Test\")\n",
    "\n",
    "print(f\"\\nüéØ Prediction generation completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd98a37",
   "metadata": {},
   "source": [
    "## 2. üìä Comprehensive Performance Metrics\n",
    "\n",
    "Let's calculate and analyze multiple performance metrics to get a complete picture of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca663768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive performance metrics calculation\n",
    "print(\"üìä COMPREHENSIVE PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "def calculate_comprehensive_metrics(y_true, y_pred, dataset_name):\n",
    "    \"\"\"Calculate comprehensive evaluation metrics for neural network\"\"\"\n",
    "    \n",
    "    # Basic regression metrics\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # MAPE with zero-division protection\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / np.maximum(np.abs(y_true), 1e-8))) * 100\n",
    "    \n",
    "    # Additional metrics\n",
    "    max_error = np.max(np.abs(y_true - y_pred))\n",
    "    std_error = np.std(y_true - y_pred)\n",
    "    \n",
    "    # Correlation coefficient\n",
    "    correlation, p_value = pearsonr(y_true, y_pred)\n",
    "    \n",
    "    # Percentage of predictions within tolerance\n",
    "    tolerance_5_percent = np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-8)) <= 0.05) * 100\n",
    "    tolerance_10_percent = np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-8)) <= 0.10) * 100\n",
    "    tolerance_20_percent = np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-8)) <= 0.20) * 100\n",
    "    \n",
    "    metrics = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R¬≤': r2,\n",
    "        'MAPE': mape,\n",
    "        'Max_Error': max_error,\n",
    "        'Std_Error': std_error,\n",
    "        'Correlation': correlation,\n",
    "        'Corr_P_Value': p_value,\n",
    "        'Within_5%': tolerance_5_percent,\n",
    "        'Within_10%': tolerance_10_percent,\n",
    "        'Within_20%': tolerance_20_percent\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for all datasets\n",
    "train_metrics = calculate_comprehensive_metrics(y_train, y_train_pred, \"Training\")\n",
    "val_metrics = calculate_comprehensive_metrics(y_val, y_val_pred, \"Validation\")\n",
    "test_metrics = calculate_comprehensive_metrics(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# Create comprehensive metrics DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Training': train_metrics,\n",
    "    'Validation': val_metrics,\n",
    "    'Testing': test_metrics\n",
    "}).round(4)\n",
    "\n",
    "print(\"üìã COMPREHENSIVE PERFORMANCE METRICS:\")\n",
    "print(\"=\" * 40)\n",
    "display(metrics_df)\n",
    "\n",
    "# Performance analysis\n",
    "print(f\"\\nüéØ PERFORMANCE ANALYSIS:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Overall accuracy assessment\n",
    "test_accuracy = test_metrics['R¬≤'] * 100\n",
    "print(f\"üìä Overall Test Accuracy: {test_accuracy:.1f}% (R¬≤ = {test_metrics['R¬≤']:.4f})\")\n",
    "\n",
    "# Error analysis\n",
    "print(f\"\udcc9 Prediction Errors on Test Set:\")\n",
    "print(f\"   RMSE: {test_metrics['RMSE']:.2f} kWh/month\")\n",
    "print(f\"   MAE: {test_metrics['MAE']:.2f} kWh/month\")\n",
    "print(f\"   MAPE: {test_metrics['MAPE']:.1f}%\")\n",
    "print(f\"   Max Error: {test_metrics['Max_Error']:.2f} kWh/month\")\n",
    "\n",
    "# Tolerance analysis\n",
    "print(f\"\\nüéØ Prediction Tolerance Analysis:\")\n",
    "print(f\"   Within 5% error: {test_metrics['Within_5%']:.1f}% of predictions\")\n",
    "print(f\"   Within 10% error: {test_metrics['Within_10%']:.1f}% of predictions\")\n",
    "print(f\"   Within 20% error: {test_metrics['Within_20%']:.1f}% of predictions\")\n",
    "\n",
    "# Overfitting assessment\n",
    "r2_diff = train_metrics['R¬≤'] - test_metrics['R¬≤']\n",
    "mae_diff = test_metrics['MAE'] - train_metrics['MAE']\n",
    "\n",
    "print(f\"\\nüßê Overfitting Assessment:\")\n",
    "print(f\"   R¬≤ difference (Train - Test): {r2_diff:.4f}\")\n",
    "print(f\"   MAE difference (Test - Train): {mae_diff:.4f}\")\n",
    "\n",
    "if r2_diff > 0.1:\n",
    "    print(\"   ‚ö†Ô∏è  Significant overfitting detected\")\n",
    "elif r2_diff > 0.05:\n",
    "    print(\"   üü° Minor overfitting detected\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No significant overfitting\")\n",
    "\n",
    "# Model quality assessment\n",
    "if test_metrics['R¬≤'] >= 0.9:\n",
    "    quality = \"Excellent\"\n",
    "elif test_metrics['R¬≤'] >= 0.8:\n",
    "    quality = \"Good\"\n",
    "elif test_metrics['R¬≤'] >= 0.7:\n",
    "    quality = \"Fair\"\n",
    "else:\n",
    "    quality = \"Poor\"\n",
    "\n",
    "print(f\"\\nüèÜ Overall Model Quality: {quality}\")\n",
    "print(f\"üìä Model meets production requirements: {'‚úÖ' if test_metrics['R¬≤'] >= 0.8 else '‚ùå'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05ca3e",
   "metadata": {},
   "source": [
    "## 3. üìà Visual Performance Analysis\n",
    "\n",
    "Let's create comprehensive visualizations to understand model performance across different dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance visualization dashboard\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=[\n",
    "        'üéØ Predicted vs Actual', 'üìä Residual Distribution',\n",
    "        'üìà Residuals vs Predicted', '‚ö° Performance by Appliance',\n",
    "        'üå°Ô∏è Performance by Season', 'üí∞ Error Distribution'\n",
    "    ],\n",
    "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    ")\n",
    "\n",
    "# Plot 1: Predicted vs Actual\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_target, y=y_pred_all,\n",
    "        mode='markers',\n",
    "        name='Predictions',\n",
    "        marker=dict(color='blue', size=4, opacity=0.6)\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Perfect prediction line\n",
    "min_val, max_val = y_target.min(), y_target.max()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[min_val, max_val], y=[min_val, max_val],\n",
    "        mode='lines',\n",
    "        name='Perfect Prediction',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Plot 2: Residual Distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=residuals,\n",
    "        nbinsx=30,\n",
    "        name='Residuals',\n",
    "        marker_color='lightblue'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Plot 3: Residuals vs Predicted\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_pred_all, y=residuals,\n",
    "        mode='markers',\n",
    "        name='Residual Pattern',\n",
    "        marker=dict(color='green', size=4, opacity=0.6)\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Zero line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[y_pred_all.min(), y_pred_all.max()], y=[0, 0],\n",
    "        mode='lines',\n",
    "        name='Zero Error',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Plot 4: Performance by Appliance\n",
    "appliance_mae = df.groupby('appliance_type').apply(\n",
    "    lambda x: mean_absolute_error(\n",
    "        x['daily_consumption_kwh'], \n",
    "        y_pred_all[x.index]\n",
    "    )\n",
    ").sort_values()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=appliance_mae.index,\n",
    "        y=appliance_mae.values,\n",
    "        name='MAE by Appliance',\n",
    "        marker_color='orange'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Plot 5: Performance by Season\n",
    "season_mae = df.groupby('season').apply(\n",
    "    lambda x: mean_absolute_error(\n",
    "        x['daily_consumption_kwh'], \n",
    "        y_pred_all[x.index]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=season_mae.index,\n",
    "        y=season_mae.values,\n",
    "        name='MAE by Season',\n",
    "        marker_color='lightcoral'\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Plot 6: Error Distribution by Range\n",
    "error_ranges = ['0-0.5', '0.5-1.0', '1.0-2.0', '2.0+']\n",
    "error_counts = [\n",
    "    np.sum(np.abs(residuals) <= 0.5),\n",
    "    np.sum((np.abs(residuals) > 0.5) & (np.abs(residuals) <= 1.0)),\n",
    "    np.sum((np.abs(residuals) > 1.0) & (np.abs(residuals) <= 2.0)),\n",
    "    np.sum(np.abs(residuals) > 2.0)\n",
    "]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=error_ranges,\n",
    "        y=error_counts,\n",
    "        name='Error Distribution',\n",
    "        marker_color='lightgreen'\n",
    "    ),\n",
    "    row=3, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1200,\n",
    "    showlegend=False,\n",
    "    title_text=\"üìä Comprehensive Model Performance Dashboard\",\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "# Update axes labels\n",
    "fig.update_xaxes(title_text=\"Actual Consumption (kWh)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Predicted Consumption (kWh)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Residuals (kWh)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Predicted Consumption (kWh)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Residuals (kWh)\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Appliance Type\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"MAE (kWh)\", row=2, col=2)\n",
    "fig.update_xaxes(title_text=\"Season\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"MAE (kWh)\", row=3, col=1)\n",
    "fig.update_xaxes(title_text=\"Error Range (kWh)\", row=3, col=2)\n",
    "fig.update_yaxes(title_text=\"Count\", row=3, col=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"üìä VISUAL ANALYSIS INSIGHTS:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"üéØ Best performing appliance: {appliance_mae.index[0]} (MAE: {appliance_mae.iloc[0]:.3f} kWh)\")\n",
    "print(f\"‚ö†Ô∏è Challenging appliance: {appliance_mae.index[-1]} (MAE: {appliance_mae.iloc[-1]:.3f} kWh)\")\n",
    "print(f\"üå°Ô∏è Best season: {season_mae.idxmin()} (MAE: {season_mae.min():.3f} kWh)\")\n",
    "print(f\"üìà Most predictions ({error_counts[0]}/{len(residuals)}) have <0.5 kWh error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d740905",
   "metadata": {},
   "source": [
    "## 4. üíº Business Impact Analysis\n",
    "\n",
    "Let's analyze the practical business implications of our model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f295728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business impact analysis\n",
    "print(\"üíº BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Cost implications\n",
    "electricity_rate = 6.0  # INR per kWh (average Indian rate)\n",
    "days_per_month = 30\n",
    "\n",
    "# Calculate monthly cost errors\n",
    "monthly_cost_errors = np.abs(residuals) * electricity_rate * days_per_month\n",
    "avg_monthly_cost_error = np.mean(monthly_cost_errors)\n",
    "max_monthly_cost_error = np.max(monthly_cost_errors)\n",
    "\n",
    "# Calculate total consumption and costs\n",
    "total_actual_monthly = y_target.sum() * days_per_month\n",
    "total_predicted_monthly = y_pred_all.sum() * days_per_month\n",
    "total_actual_cost = total_actual_monthly * electricity_rate\n",
    "total_predicted_cost = total_predicted_monthly * electricity_rate\n",
    "\n",
    "print(\"üí∞ COST IMPACT ANALYSIS:\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"   üìä Average monthly cost error: ‚Çπ{avg_monthly_cost_error:.2f} per appliance\")\n",
    "print(f\"   üìà Maximum monthly cost error: ‚Çπ{max_monthly_cost_error:.2f} per appliance\")\n",
    "print(f\"   üìã Median monthly cost error: ‚Çπ{np.median(monthly_cost_errors):.2f} per appliance\")\n",
    "\n",
    "# Error by appliance type\n",
    "print(\"\\n‚ö° ERROR BY APPLIANCE TYPE:\")\n",
    "print(\"-\" * 30)\n",
    "for appliance in df['appliance_type'].unique():\n",
    "    mask = df['appliance_type'] == appliance\n",
    "    appliance_errors = monthly_cost_errors[mask]\n",
    "    avg_error = np.mean(appliance_errors)\n",
    "    print(f\"   üìä {appliance}: ‚Çπ{avg_error:.2f}/month average error\")\n",
    "\n",
    "# Model reliability assessment\n",
    "print(\"\\nüõ°Ô∏è MODEL RELIABILITY ASSESSMENT:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "reliable_predictions = np.sum(np.abs(residuals) <= 0.5) / len(residuals) * 100\n",
    "acceptable_predictions = np.sum(np.abs(residuals) <= 1.0) / len(residuals) * 100\n",
    "\n",
    "print(f\"   ‚úÖ Highly reliable predictions (‚â§0.5 kWh error): {reliable_predictions:.1f}%\")\n",
    "print(f\"   üëç Acceptable predictions (‚â§1.0 kWh error): {acceptable_predictions:.1f}%\")\n",
    "\n",
    "# Business recommendations\n",
    "print(\"\\nüìã BUSINESS RECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "if reliable_predictions > 70:\n",
    "    print(\"   üåü Excellent reliability - ready for production deployment\")\n",
    "    print(\"   ‚úÖ Can be used for energy planning and cost estimation\")\n",
    "elif reliable_predictions > 50:\n",
    "    print(\"   üëç Good reliability - suitable for most applications\")\n",
    "    print(\"   ‚ö†Ô∏è Consider confidence intervals for critical decisions\")\n",
    "else:\n",
    "    print(\"   ‚ùå Limited reliability - needs improvement before deployment\")\n",
    "    print(\"   üîß Consider collecting more data or feature engineering\")\n",
    "\n",
    "print(f\"\\nüí° For household energy management, this model can save families\")\n",
    "print(f\"   an average of ‚Çπ{avg_monthly_cost_error:.0f}/month in prediction accuracy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba26ff7",
   "metadata": {},
   "source": [
    "## 5. üìù Model Evaluation Summary and Recommendations\n",
    "\n",
    "Let's create a comprehensive summary of our model evaluation findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive evaluation summary\n",
    "print(\"üìù COMPREHENSIVE MODEL EVALUATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Executive Summary\n",
    "print(\"üéØ EXECUTIVE SUMMARY:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"   üß† Model Type: Neural Network (TensorFlow/Keras)\")\n",
    "print(f\"   üìä Dataset Size: {len(df):,} appliances from {df['household_id'].nunique()} households\")\n",
    "print(f\"   üéØ Target Variable: Daily Energy Consumption (kWh)\")\n",
    "print(f\"   üìà Overall Performance: {performance_level}\")\n",
    "print(f\"   üìä Accuracy (R¬≤): {r2:.3f} ({r2*100:.1f}% variance explained)\")\n",
    "print(f\"   üí∞ Average Cost Error: ‚Çπ{avg_monthly_cost_error:.2f}/month per appliance\")\n",
    "\n",
    "# Strengths\n",
    "print(\"\\nüí™ MODEL STRENGTHS:\")\n",
    "print(\"-\" * 20)\n",
    "strengths = []\n",
    "if r2 > 0.7:\n",
    "    strengths.append(\"High predictive accuracy\")\n",
    "if within_20_percent > 80:\n",
    "    strengths.append(\"Most predictions within 20% error\")\n",
    "if abs(mean_residual) < 0.1:\n",
    "    strengths.append(\"Low systematic bias\")\n",
    "\n",
    "for i, strength in enumerate(strengths, 1):\n",
    "    print(f\"   {i}. ‚úÖ {strength}\")\n",
    "\n",
    "# Deployment Readiness\n",
    "print(\"\\nüöÄ DEPLOYMENT READINESS:\")\n",
    "print(\"-\" * 25)\n",
    "deployment_score = 0\n",
    "max_score = 5\n",
    "\n",
    "# Scoring criteria\n",
    "if r2 > 0.7: deployment_score += 1\n",
    "if within_20_percent > 75: deployment_score += 1\n",
    "if abs(mean_residual) < 0.2: deployment_score += 1\n",
    "if avg_monthly_cost_error < 100: deployment_score += 1\n",
    "if reliable_predictions > 60: deployment_score += 1\n",
    "\n",
    "deployment_percentage = (deployment_score / max_score) * 100\n",
    "\n",
    "print(f\"   üìä Deployment Score: {deployment_score}/{max_score} ({deployment_percentage:.0f}%)\")\n",
    "\n",
    "if deployment_percentage >= 80:\n",
    "    readiness = \"üü¢ Ready for Production\"\n",
    "    recommendation = \"Deploy with confidence\"\n",
    "elif deployment_percentage >= 60:\n",
    "    readiness = \"üü° Ready with Monitoring\"\n",
    "    recommendation = \"Deploy with careful monitoring\"\n",
    "else:\n",
    "    readiness = \"üî¥ Needs Improvement\"\n",
    "    recommendation = \"Improve before deployment\"\n",
    "\n",
    "print(f\"   üéØ Status: {readiness}\")\n",
    "print(f\"   üí° Recommendation: {recommendation}\")\n",
    "\n",
    "# Final Recommendations\n",
    "print(\"\\nüìã FINAL RECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"   1. üì± Integrate model into web application for user predictions\")\n",
    "print(\"   2. üîÑ Implement model monitoring and performance tracking\")\n",
    "print(\"   3. üìä Collect user feedback to improve future versions\")\n",
    "print(\"   4. ‚öñÔ∏è Add confidence intervals for critical business decisions\")\n",
    "print(\"   5. üîß Consider ensemble methods for improved robustness\")\n",
    "\n",
    "# Save evaluation results\n",
    "evaluation_results = {\n",
    "    'r2_score': r2,\n",
    "    'mae': mae,\n",
    "    'rmse': rmse,\n",
    "    'mape': mape,\n",
    "    'within_20_percent': within_20_percent,\n",
    "    'avg_monthly_cost_error': avg_monthly_cost_error,\n",
    "    'deployment_score': deployment_score,\n",
    "    'deployment_percentage': deployment_percentage,\n",
    "    'best_appliance': appliance_mae.index[0],\n",
    "    'worst_appliance': appliance_mae.index[-1]\n",
    "}\n",
    "\n",
    "joblib.dump(evaluation_results, '../models/evaluation_results.pkl')\n",
    "print(\"\\nüíæ Evaluation results saved for future reference!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéâ MODEL EVALUATION COMPLETE!\")\n",
    "print(f\"‚úÖ Your neural network is ready for {recommendation.lower()}!\")\n",
    "print(\"üöÄ Next step: Deploy in the web application!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b51fce",
   "metadata": {},
   "source": [
    "# üìä Model Evaluation and Performance Analysis\n",
    "\n",
    "**Comprehensive Analysis of Neural Network Performance for Appliance Energy Prediction**\n",
    "\n",
    "This notebook provides in-depth evaluation of our trained neural network model. You'll learn how to assess model performance, identify strengths and weaknesses, and validate the model for real-world deployment.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "1. **Load and test** the trained neural network model\n",
    "2. **Comprehensive evaluation** using multiple metrics\n",
    "3. **Cross-validation** for robust performance assessment\n",
    "4. **Feature importance** analysis\n",
    "5. **Model interpretation** and business insights\n",
    "6. **Deployment readiness** assessment\n",
    "\n",
    "## üìä Evaluation Approach\n",
    "- **Accuracy Metrics**: R¬≤, MSE, MAE, MAPE\n",
    "- **Visual Analysis**: Prediction plots, residual analysis\n",
    "- **Statistical Tests**: Distribution analysis, bias detection\n",
    "- **Business Metrics**: Cost implications, practical accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest, shapiro\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style and random seeds\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"üìä MODEL EVALUATION SETUP COMPLETE!\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üß† TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"üìà Ready to evaluate neural network performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e6ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320481d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87352857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6aa181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3260c145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
