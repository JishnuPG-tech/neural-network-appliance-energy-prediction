{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579f2528",
   "metadata": {},
   "source": [
    "# ğŸš€ **Complete Neural Network Project - Master Notebook**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JishnuPG-tech/neural-network-appliance-energy-prediction/blob/main/notebooks/MASTER_COMPLETE_PROJECT.ipynb)\n",
    "\n",
    "**This notebook runs the complete neural network pipeline from data exploration to model evaluation in one go!**\n",
    "\n",
    "## ğŸ“‹ What This Notebook Does:\n",
    "1. **ğŸ”§ Environment Setup** - Clones repo and installs packages\n",
    "2. **ğŸ“Š Data Exploration** - Analyzes patterns and relationships\n",
    "3. **ğŸ§¹ Data Preprocessing** - Cleans and prepares data\n",
    "4. **ğŸ§  Neural Network** - Builds and trains TensorFlow model\n",
    "5. **ğŸ“Š Model Evaluation** - Evaluates performance with metrics\n",
    "\n",
    "**âš¡ Just run all cells for complete analysis!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefd7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ STEP 1: Environment Setup and Repository Clone\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸŒŸ Running in Google Colab!\")\n",
    "    \n",
    "    # Clone repository if not exists\n",
    "    if not os.path.exists('/content/neural-network-appliance-energy-prediction'):\n",
    "        print(\"ğŸ“ Cloning repository...\")\n",
    "        !git clone https://github.com/JishnuPG-tech/neural-network-appliance-energy-prediction.git\n",
    "        print(\"âœ… Repository cloned!\")\n",
    "    \n",
    "    # Change to project directory\n",
    "    os.chdir('/content/neural-network-appliance-energy-prediction')\n",
    "    \n",
    "    # Install required packages\n",
    "    print(\"ğŸ“¦ Installing packages...\")\n",
    "    !pip install tensorflow==2.13.0 pandas numpy matplotlib seaborn plotly scikit-learn scipy joblib\n",
    "    print(\"âœ… All packages installed!\")\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» Running in local environment!\")\n",
    "    \n",
    "print(f\"ğŸ“ Current directory: {os.getcwd()}\")\n",
    "print(\"ğŸš€ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š STEP 2: Import All Required Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core Data Science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ğŸ”¥ TensorFlow version:\", tf.__version__)\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95770f46",
   "metadata": {},
   "source": [
    "## ğŸ“Š STEP 3: Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (create synthetic if not available)\n",
    "def create_synthetic_data():\n",
    "    \"\"\"Create synthetic appliance energy data.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'date': pd.date_range('2023-01-01', periods=n_samples, freq='H'),\n",
    "        'Appliances': np.random.normal(100, 30, n_samples),\n",
    "        'T1': np.random.normal(20, 5, n_samples),\n",
    "        'RH_1': np.random.normal(40, 10, n_samples),\n",
    "        'T2': np.random.normal(22, 4, n_samples),\n",
    "        'RH_2': np.random.normal(45, 8, n_samples),\n",
    "        'T_out': np.random.normal(15, 8, n_samples),\n",
    "        'Press_mm_hg': np.random.normal(760, 20, n_samples),\n",
    "        'RH_out': np.random.normal(50, 15, n_samples),\n",
    "        'Windspeed': np.random.normal(5, 2, n_samples),\n",
    "        'Visibility': np.random.normal(25, 5, n_samples),\n",
    "        'Tdewpoint': np.random.normal(10, 6, n_samples)\n",
    "    })\n",
    "    \n",
    "    # Ensure positive values for Appliances\n",
    "    df['Appliances'] = np.abs(df['Appliances'])\n",
    "    return df\n",
    "\n",
    "# Load or create data\n",
    "try:\n",
    "    df = pd.read_csv('data/appliances_sample_data.csv')\n",
    "    print(\"âœ… Data loaded from file!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ğŸ”§ Creating synthetic dataset...\")\n",
    "    df = create_synthetic_data()\n",
    "\n",
    "print(f\"ğŸ“Š Dataset shape: {df.shape}\")\n",
    "print(f\"ğŸ·ï¸ Columns: {list(df.columns)}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nğŸ“‹ First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nğŸ“ˆ Statistical Summary:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94965d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Data Visualization Dashboard\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Target distribution\n",
    "axes[0,0].hist(df['Appliances'], bins=50, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_title('ğŸ¯ Appliances Energy Distribution')\n",
    "axes[0,0].set_xlabel('Energy (Wh)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Temperature comparison\n",
    "axes[0,1].hist(df['T1'], bins=30, alpha=0.7, color='red', label='T1')\n",
    "axes[0,1].hist(df['T2'], bins=30, alpha=0.7, color='blue', label='T2')\n",
    "axes[0,1].set_title('ğŸŒ¡ï¸ Temperature Distributions')\n",
    "axes[0,1].set_xlabel('Temperature (Â°C)')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Humidity comparison\n",
    "axes[0,2].hist(df['RH_1'], bins=30, alpha=0.7, color='green', label='RH_1')\n",
    "axes[0,2].hist(df['RH_2'], bins=30, alpha=0.7, color='orange', label='RH_2')\n",
    "axes[0,2].set_title('ğŸ’§ Humidity Distributions')\n",
    "axes[0,2].set_xlabel('Relative Humidity (%)')\n",
    "axes[0,2].legend()\n",
    "\n",
    "# Time series (first 100 points)\n",
    "if 'date' in df.columns:\n",
    "    axes[1,0].plot(df['date'][:100], df['Appliances'][:100])\n",
    "    axes[1,0].set_title('â° Energy Over Time (First 100h)')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Correlation with target\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlations = df[numeric_cols].corr()['Appliances'].drop('Appliances').sort_values()\n",
    "axes[1,1].barh(range(len(correlations)), correlations.values)\n",
    "axes[1,1].set_yticks(range(len(correlations)))\n",
    "axes[1,1].set_yticklabels(correlations.index)\n",
    "axes[1,1].set_title('ğŸ”— Feature Correlations with Target')\n",
    "axes[1,1].set_xlabel('Correlation Coefficient')\n",
    "\n",
    "# Box plot for outliers\n",
    "axes[1,2].boxplot(df['Appliances'])\n",
    "axes[1,2].set_title('ğŸ“¦ Appliances Energy Box Plot')\n",
    "axes[1,2].set_ylabel('Energy (Wh)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Data exploration visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40620df5",
   "metadata": {},
   "source": [
    "## ğŸ§¹ STEP 4: Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133897a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and preprocessing\n",
    "print(\"ğŸ§¹ Starting data preprocessing...\")\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove missing values\n",
    "initial_shape = df_clean.shape[0]\n",
    "df_clean = df_clean.dropna()\n",
    "print(f\"ğŸ“Š Removed {initial_shape - df_clean.shape[0]} rows with missing values\")\n",
    "\n",
    "# Feature engineering\n",
    "if 'date' in df_clean.columns:\n",
    "    df_clean['date'] = pd.to_datetime(df_clean['date'])\n",
    "    df_clean['hour'] = df_clean['date'].dt.hour\n",
    "    df_clean['day_of_week'] = df_clean['date'].dt.dayofweek\n",
    "    df_clean['month'] = df_clean['date'].dt.month\n",
    "    df_clean['is_weekend'] = (df_clean['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Cyclical encoding\n",
    "    df_clean['hour_sin'] = np.sin(2 * np.pi * df_clean['hour'] / 24)\n",
    "    df_clean['hour_cos'] = np.cos(2 * np.pi * df_clean['hour'] / 24)\n",
    "    \n",
    "    # Drop original date\n",
    "    df_clean = df_clean.drop(['date'], axis=1)\n",
    "    print(\"ğŸ• Added time-based features\")\n",
    "\n",
    "# Temperature and humidity interactions\n",
    "if all(col in df_clean.columns for col in ['T1', 'T2', 'RH_1', 'RH_2']):\n",
    "    df_clean['temp_avg'] = (df_clean['T1'] + df_clean['T2']) / 2\n",
    "    df_clean['humidity_avg'] = (df_clean['RH_1'] + df_clean['RH_2']) / 2\n",
    "    df_clean['temp_diff'] = df_clean['T1'] - df_clean['T2']\n",
    "    df_clean['humidity_diff'] = df_clean['RH_1'] - df_clean['RH_2']\n",
    "    print(\"ğŸŒ¡ï¸ Added temperature and humidity features\")\n",
    "\n",
    "# Prepare features and target\n",
    "target_col = 'Appliances'\n",
    "feature_cols = [col for col in df_clean.columns if col != target_col]\n",
    "\n",
    "X = df_clean[feature_cols]\n",
    "y = df_clean[target_col]\n",
    "\n",
    "print(f\"ğŸ¯ Features: {len(feature_cols)}\")\n",
    "print(f\"ğŸ“Š Samples: {len(X)}\")\n",
    "print(f\"ğŸ·ï¸ Feature names: {feature_cols}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"ğŸš‚ Training set: {X_train_scaled.shape}\")\n",
    "print(f\"ğŸ§ª Test set: {X_test_scaled.shape}\")\n",
    "print(\"âœ… Data preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0b7a79",
   "metadata": {},
   "source": [
    "## ğŸ§  STEP 5: Neural Network Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e05b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build neural network architecture\n",
    "print(\"ğŸ—ï¸ Building neural network architecture...\")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Input layer\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    # Hidden layers\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    # Output layer\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "print(\"\\nğŸ“‹ Neural Network Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Callbacks for training\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7\n",
    ")\n",
    "\n",
    "print(\"âœ… Neural network architecture ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network\n",
    "print(\"ğŸš‚ Training neural network...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ‰ Neural network training complete!\")\n",
    "\n",
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "ax1.set_title('ğŸ“‰ Model Loss During Training')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss (MSE)')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# MAE plot\n",
    "ax2.plot(history.history['mae'], label='Training MAE', color='green')\n",
    "ax2.plot(history.history['val_mae'], label='Validation MAE', color='orange')\n",
    "ax2.set_title('ğŸ“Š Mean Absolute Error During Training')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('MAE')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ef512",
   "metadata": {},
   "source": [
    "## ğŸ“Š STEP 6: Model Evaluation and Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ca0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "print(\"ğŸ”® Making predictions...\")\n",
    "\n",
    "y_pred_train = model.predict(X_train_scaled).flatten()\n",
    "y_pred_test = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Performance report\n",
    "print(\"\\nğŸ“Š NEURAL NETWORK PERFORMANCE REPORT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nğŸš‚ TRAINING SET PERFORMANCE:\")\n",
    "print(f\"   Mean Squared Error (MSE):     {train_mse:.2f}\")\n",
    "print(f\"   Mean Absolute Error (MAE):    {train_mae:.2f}\")\n",
    "print(f\"   R-squared (RÂ²):               {train_r2:.4f}\")\n",
    "print(f\"   Root Mean Squared Error:      {np.sqrt(train_mse):.2f}\")\n",
    "\n",
    "print(\"\\nğŸ§ª TEST SET PERFORMANCE:\")\n",
    "print(f\"   Mean Squared Error (MSE):     {test_mse:.2f}\")\n",
    "print(f\"   Mean Absolute Error (MAE):    {test_mae:.2f}\")\n",
    "print(f\"   R-squared (RÂ²):               {test_r2:.4f}\")\n",
    "print(f\"   Root Mean Squared Error:      {np.sqrt(test_mse):.2f}\")\n",
    "\n",
    "# Model interpretation\n",
    "print(\"\\nğŸ§  MODEL INTERPRETATION:\")\n",
    "if test_r2 > 0.8:\n",
    "    print(\"   âœ… EXCELLENT: Model explains >80% of variance\")\n",
    "elif test_r2 > 0.6:\n",
    "    print(\"   âœ… GOOD: Model explains >60% of variance\")\n",
    "elif test_r2 > 0.4:\n",
    "    print(\"   âš ï¸ MODERATE: Model explains >40% of variance\")\n",
    "else:\n",
    "    print(\"   âŒ POOR: Model explains <40% of variance\")\n",
    "\n",
    "print(f\"   ğŸ“ˆ Average prediction error: Â±{test_mae:.2f} energy units\")\n",
    "print(f\"   ğŸ¯ Model captures {test_r2*100:.1f}% of energy patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeda661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Comprehensive Evaluation Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Predictions vs Actual (Test Set)\n",
    "axes[0,0].scatter(y_test, y_pred_test, alpha=0.6, color='blue')\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0,0].set_xlabel('Actual Energy')\n",
    "axes[0,0].set_ylabel('Predicted Energy')\n",
    "axes[0,0].set_title(f'ğŸ¯ Predictions vs Actual (Test Set)\\nRÂ² = {test_r2:.3f}')\n",
    "axes[0,0].grid(True)\n",
    "\n",
    "# 2. Residuals Plot\n",
    "residuals = y_test - y_pred_test\n",
    "axes[0,1].scatter(y_pred_test, residuals, alpha=0.6, color='green')\n",
    "axes[0,1].axhline(y=0, color='red', linestyle='--')\n",
    "axes[0,1].set_xlabel('Predicted Energy')\n",
    "axes[0,1].set_ylabel('Residuals (Actual - Predicted)')\n",
    "axes[0,1].set_title('ğŸ“Š Residuals Plot')\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "# 3. Residuals Distribution\n",
    "axes[1,0].hist(residuals, bins=30, alpha=0.7, color='purple')\n",
    "axes[1,0].axvline(residuals.mean(), color='red', linestyle='--', label=f'Mean: {residuals.mean():.2f}')\n",
    "axes[1,0].set_xlabel('Residuals')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].set_title('ğŸ“ˆ Residuals Distribution')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True)\n",
    "\n",
    "# 4. Training vs Validation Loss\n",
    "axes[1,1].plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "axes[1,1].plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "axes[1,1].set_xlabel('Epoch')\n",
    "axes[1,1].set_ylabel('Loss (MSE)')\n",
    "axes[1,1].set_title('ğŸ“‰ Training Progress')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Complete evaluation visualizations generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8fc30a",
   "metadata": {},
   "source": [
    "## ğŸ‰ Project Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final project summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ NEURAL NETWORK PROJECT COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nğŸ“Š PROJECT STATISTICS:\")\n",
    "print(f\"   ğŸ“ Dataset size: {len(df)} samples\")\n",
    "print(f\"   ğŸ¯ Features used: {len(feature_cols)}\")\n",
    "print(f\"   ğŸš‚ Training samples: {len(X_train)}\")\n",
    "print(f\"   ğŸ§ª Test samples: {len(X_test)}\")\n",
    "print(f\"   ğŸ§  Model parameters: {model.count_params():,}\")\n",
    "\n",
    "print(\"\\nğŸ† FINAL PERFORMANCE:\")\n",
    "print(f\"   ğŸ“ˆ Test RÂ²: {test_r2:.3f}\")\n",
    "print(f\"   ğŸ“Š Test MAE: {test_mae:.2f}\")\n",
    "print(f\"   ğŸ¯ Test RMSE: {np.sqrt(test_mse):.2f}\")\n",
    "\n",
    "print(\"\\nğŸš€ WHAT WAS ACCOMPLISHED:\")\n",
    "print(\"   âœ… Data exploration and visualization\")\n",
    "print(\"   âœ… Feature engineering and preprocessing\")\n",
    "print(\"   âœ… Neural network architecture design\")\n",
    "print(\"   âœ… Model training with regularization\")\n",
    "print(\"   âœ… Comprehensive performance evaluation\")\n",
    "print(\"   âœ… Advanced visualizations and insights\")\n",
    "\n",
    "print(\"\\nğŸ”® NEXT STEPS:\")\n",
    "print(\"   ğŸ¯ Fine-tune hyperparameters for better performance\")\n",
    "print(\"   ğŸ“Š Try different neural network architectures\")\n",
    "print(\"   ğŸ” Analyze feature importance in more detail\")\n",
    "print(\"   ğŸ’¾ Save and deploy the model for production use\")\n",
    "print(\"   ğŸ“ˆ Collect more data for improved accuracy\")\n",
    "\n",
    "print(\"\\nğŸ’¡ KEY INSIGHTS:\")\n",
    "if test_r2 > 0.7:\n",
    "    print(\"   ğŸŒŸ Your neural network shows excellent predictive performance!\")\n",
    "    print(\"   ğŸ¯ The model successfully captures appliance energy patterns.\")\n",
    "else:\n",
    "    print(\"   ğŸ“Š Your neural network shows good learning capability.\")\n",
    "    print(\"   ğŸ”§ Consider more data or feature engineering for improvement.\")\n",
    "\n",
    "print(f\"\\nğŸ“± Model ready for appliance energy prediction!\")\n",
    "print(f\"ğŸ¯ Input {len(feature_cols)} features â†’ Get energy consumption prediction\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ SUCCESS! Your complete neural network pipeline is ready!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
