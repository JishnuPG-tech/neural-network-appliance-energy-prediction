{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579f2528",
   "metadata": {},
   "source": [
    "# üöÄ **Complete Neural Network Project - Master Notebook**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JishnuPG-tech/neural-network-appliance-energy-prediction/blob/main/notebooks/MASTER_COMPLETE_PROJECT.ipynb)\n",
    "\n",
    "**This notebook runs the complete neural network pipeline from data exploration to model evaluation in one go!**\n",
    "\n",
    "## üìã What This Notebook Does:\n",
    "1. **üîß Environment Setup** - Clones repo and installs packages\n",
    "2. **üìä Data Exploration** - Analyzes patterns and relationships\n",
    "3. **üßπ Data Preprocessing** - Cleans and prepares data\n",
    "4. **üß† Neural Network** - Builds and trains TensorFlow model\n",
    "5. **üìä Model Evaluation** - Evaluates performance with metrics\n",
    "\n",
    "**‚ö° Just run all cells for complete analysis!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefd7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß STEP 1: Environment Setup and Repository Clone\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üåü Running in Google Colab!\")\n",
    "    \n",
    "    # Clone repository if not exists\n",
    "    if not os.path.exists('/content/neural-network-appliance-energy-prediction'):\n",
    "        print(\"üìÅ Cloning repository...\")\n",
    "        !git clone https://github.com/JishnuPG-tech/neural-network-appliance-energy-prediction.git\n",
    "        print(\"‚úÖ Repository cloned!\")\n",
    "    \n",
    "    # Change to project directory\n",
    "    os.chdir('/content/neural-network-appliance-energy-prediction')\n",
    "    \n",
    "    # Install required packages\n",
    "    print(\"üì¶ Installing packages...\")\n",
    "    !pip install tensorflow==2.13.0 pandas numpy matplotlib seaborn plotly scikit-learn scipy joblib\n",
    "    print(\"‚úÖ All packages installed!\")\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Running in local environment!\")\n",
    "    \n",
    "print(f\"üìç Current directory: {os.getcwd()}\")\n",
    "print(\"üöÄ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö STEP 2: Import All Required Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core Data Science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üî• TensorFlow version:\", tf.__version__)\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95770f46",
   "metadata": {},
   "source": [
    "## üìä STEP 3: Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (create synthetic if not available)\n",
    "def create_synthetic_data():\n",
    "    \"\"\"Create synthetic appliance energy data.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'date': pd.date_range('2023-01-01', periods=n_samples, freq='H'),\n",
    "        'Appliances': np.random.normal(100, 30, n_samples),\n",
    "        'T1': np.random.normal(20, 5, n_samples),\n",
    "        'RH_1': np.random.normal(40, 10, n_samples),\n",
    "        'T2': np.random.normal(22, 4, n_samples),\n",
    "        'RH_2': np.random.normal(45, 8, n_samples),\n",
    "        'T_out': np.random.normal(15, 8, n_samples),\n",
    "        'Press_mm_hg': np.random.normal(760, 20, n_samples),\n",
    "        'RH_out': np.random.normal(50, 15, n_samples),\n",
    "        'Windspeed': np.random.normal(5, 2, n_samples),\n",
    "        'Visibility': np.random.normal(25, 5, n_samples),\n",
    "        'Tdewpoint': np.random.normal(10, 6, n_samples)\n",
    "    })\n",
    "    \n",
    "    # Ensure positive values for Appliances\n",
    "    df['Appliances'] = np.abs(df['Appliances'])\n",
    "    return df\n",
    "\n",
    "# Load or create data\n",
    "try:\n",
    "    df = pd.read_csv('data/appliances_sample_data.csv')\n",
    "    print(\"‚úÖ Data loaded from file!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"üîß Creating synthetic dataset...\")\n",
    "    df = create_synthetic_data()\n",
    "\n",
    "print(f\"üìä Dataset shape: {df.shape}\")\n",
    "print(f\"üè∑Ô∏è Columns: {list(df.columns)}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nüìã First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nüìà Statistical Summary:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94965d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Data Visualization Dashboard\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Target distribution\n",
    "axes[0,0].hist(df['Appliances'], bins=50, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_title('üéØ Appliances Energy Distribution')\n",
    "axes[0,0].set_xlabel('Energy (Wh)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Temperature comparison\n",
    "axes[0,1].hist(df['T1'], bins=30, alpha=0.7, color='red', label='T1')\n",
    "axes[0,1].hist(df['T2'], bins=30, alpha=0.7, color='blue', label='T2')\n",
    "axes[0,1].set_title('üå°Ô∏è Temperature Distributions')\n",
    "axes[0,1].set_xlabel('Temperature (¬∞C)')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Humidity comparison\n",
    "axes[0,2].hist(df['RH_1'], bins=30, alpha=0.7, color='green', label='RH_1')\n",
    "axes[0,2].hist(df['RH_2'], bins=30, alpha=0.7, color='orange', label='RH_2')\n",
    "axes[0,2].set_title('üíß Humidity Distributions')\n",
    "axes[0,2].set_xlabel('Relative Humidity (%)')\n",
    "axes[0,2].legend()\n",
    "\n",
    "# Time series (first 100 points)\n",
    "if 'date' in df.columns:\n",
    "    axes[1,0].plot(df['date'][:100], df['Appliances'][:100])\n",
    "    axes[1,0].set_title('‚è∞ Energy Over Time (First 100h)')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Correlation with target\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlations = df[numeric_cols].corr()['Appliances'].drop('Appliances').sort_values()\n",
    "axes[1,1].barh(range(len(correlations)), correlations.values)\n",
    "axes[1,1].set_yticks(range(len(correlations)))\n",
    "axes[1,1].set_yticklabels(correlations.index)\n",
    "axes[1,1].set_title('üîó Feature Correlations with Target')\n",
    "axes[1,1].set_xlabel('Correlation Coefficient')\n",
    "\n",
    "# Box plot for outliers\n",
    "axes[1,2].boxplot(df['Appliances'])\n",
    "axes[1,2].set_title('üì¶ Appliances Energy Box Plot')\n",
    "axes[1,2].set_ylabel('Energy (Wh)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Data exploration visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40620df5",
   "metadata": {},
   "source": [
    "## üßπ STEP 4: Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133897a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and preprocessing\n",
    "print(\"üßπ Starting data preprocessing...\")\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove missing values\n",
    "initial_shape = df_clean.shape[0]\n",
    "df_clean = df_clean.dropna()\n",
    "print(f\"üìä Removed {initial_shape - df_clean.shape[0]} rows with missing values\")\n",
    "\n",
    "# Feature engineering\n",
    "if 'date' in df_clean.columns:\n",
    "    df_clean['date'] = pd.to_datetime(df_clean['date'])\n",
    "    df_clean['hour'] = df_clean['date'].dt.hour\n",
    "    df_clean['day_of_week'] = df_clean['date'].dt.dayofweek\n",
    "    df_clean['month'] = df_clean['date'].dt.month\n",
    "    df_clean['is_weekend'] = (df_clean['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Cyclical encoding\n",
    "    df_clean['hour_sin'] = np.sin(2 * np.pi * df_clean['hour'] / 24)\n",
    "    df_clean['hour_cos'] = np.cos(2 * np.pi * df_clean['hour'] / 24)\n",
    "    \n",
    "    # Drop original date\n",
    "    df_clean = df_clean.drop(['date'], axis=1)\n",
    "    print(\"üïê Added time-based features\")\n",
    "\n",
    "# Temperature and humidity interactions\n",
    "if all(col in df_clean.columns for col in ['T1', 'T2', 'RH_1', 'RH_2']):\n",
    "    df_clean['temp_avg'] = (df_clean['T1'] + df_clean['T2']) / 2\n",
    "    df_clean['humidity_avg'] = (df_clean['RH_1'] + df_clean['RH_2']) / 2\n",
    "    df_clean['temp_diff'] = df_clean['T1'] - df_clean['T2']\n",
    "    df_clean['humidity_diff'] = df_clean['RH_1'] - df_clean['RH_2']\n",
    "    print(\"üå°Ô∏è Added temperature and humidity features\")\n",
    "\n",
    "# Prepare features and target\n",
    "target_col = 'Appliances'\n",
    "feature_cols = [col for col in df_clean.columns if col != target_col]\n",
    "\n",
    "X = df_clean[feature_cols]\n",
    "y = df_clean[target_col]\n",
    "\n",
    "print(f\"üéØ Features: {len(feature_cols)}\")\n",
    "print(f\"üìä Samples: {len(X)}\")\n",
    "print(f\"üè∑Ô∏è Feature names: {feature_cols}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"üöÇ Training set: {X_train_scaled.shape}\")\n",
    "print(f\"üß™ Test set: {X_test_scaled.shape}\")\n",
    "print(\"‚úÖ Data preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0b7a79",
   "metadata": {},
   "source": [
    "## üß† STEP 5: Neural Network Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e05b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build neural network architecture\n",
    "print(\"üèóÔ∏è Building neural network architecture...\")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Input layer\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    # Hidden layers\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    # Output layer\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "print(\"\\nüìã Neural Network Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Callbacks for training\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Neural network architecture ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network\n",
    "print(\"üöÇ Training neural network...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nüéâ Neural network training complete!\")\n",
    "\n",
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "ax1.set_title('üìâ Model Loss During Training')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss (MSE)')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# MAE plot\n",
    "ax2.plot(history.history['mae'], label='Training MAE', color='green')\n",
    "ax2.plot(history.history['val_mae'], label='Validation MAE', color='orange')\n",
    "ax2.set_title('üìä Mean Absolute Error During Training')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('MAE')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ef512",
   "metadata": {},
   "source": [
    "## üìä STEP 6: Model Evaluation and Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ca0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "print(\"üîÆ Making predictions...\")\n",
    "\n",
    "y_pred_train = model.predict(X_train_scaled).flatten()\n",
    "y_pred_test = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Performance report\n",
    "print(\"\\nüìä NEURAL NETWORK PERFORMANCE REPORT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nüöÇ TRAINING SET PERFORMANCE:\")\n",
    "print(f\"   Mean Squared Error (MSE):     {train_mse:.2f}\")\n",
    "print(f\"   Mean Absolute Error (MAE):    {train_mae:.2f}\")\n",
    "print(f\"   R-squared (R¬≤):               {train_r2:.4f}\")\n",
    "print(f\"   Root Mean Squared Error:      {np.sqrt(train_mse):.2f}\")\n",
    "\n",
    "print(\"\\nüß™ TEST SET PERFORMANCE:\")\n",
    "print(f\"   Mean Squared Error (MSE):     {test_mse:.2f}\")\n",
    "print(f\"   Mean Absolute Error (MAE):    {test_mae:.2f}\")\n",
    "print(f\"   R-squared (R¬≤):               {test_r2:.4f}\")\n",
    "print(f\"   Root Mean Squared Error:      {np.sqrt(test_mse):.2f}\")\n",
    "\n",
    "# Model interpretation\n",
    "print(\"\\nüß† MODEL INTERPRETATION:\")\n",
    "if test_r2 > 0.8:\n",
    "    print(\"   ‚úÖ EXCELLENT: Model explains >80% of variance\")\n",
    "elif test_r2 > 0.6:\n",
    "    print(\"   ‚úÖ GOOD: Model explains >60% of variance\")\n",
    "elif test_r2 > 0.4:\n",
    "    print(\"   ‚ö†Ô∏è MODERATE: Model explains >40% of variance\")\n",
    "else:\n",
    "    print(\"   ‚ùå POOR: Model explains <40% of variance\")\n",
    "\n",
    "print(f\"   üìà Average prediction error: ¬±{test_mae:.2f} energy units\")\n",
    "print(f\"   üéØ Model captures {test_r2*100:.1f}% of energy patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeda661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Comprehensive Evaluation Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Predictions vs Actual (Test Set)\n",
    "axes[0,0].scatter(y_test, y_pred_test, alpha=0.6, color='blue')\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0,0].set_xlabel('Actual Energy')\n",
    "axes[0,0].set_ylabel('Predicted Energy')\n",
    "axes[0,0].set_title(f'üéØ Predictions vs Actual (Test Set)\\nR¬≤ = {test_r2:.3f}')\n",
    "axes[0,0].grid(True)\n",
    "\n",
    "# 2. Residuals Plot\n",
    "residuals = y_test - y_pred_test\n",
    "axes[0,1].scatter(y_pred_test, residuals, alpha=0.6, color='green')\n",
    "axes[0,1].axhline(y=0, color='red', linestyle='--')\n",
    "axes[0,1].set_xlabel('Predicted Energy')\n",
    "axes[0,1].set_ylabel('Residuals (Actual - Predicted)')\n",
    "axes[0,1].set_title('üìä Residuals Plot')\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "# 3. Residuals Distribution\n",
    "axes[1,0].hist(residuals, bins=30, alpha=0.7, color='purple')\n",
    "axes[1,0].axvline(residuals.mean(), color='red', linestyle='--', label=f'Mean: {residuals.mean():.2f}')\n",
    "axes[1,0].set_xlabel('Residuals')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].set_title('üìà Residuals Distribution')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True)\n",
    "\n",
    "# 4. Training vs Validation Loss\n",
    "axes[1,1].plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "axes[1,1].plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "axes[1,1].set_xlabel('Epoch')\n",
    "axes[1,1].set_ylabel('Loss (MSE)')\n",
    "axes[1,1].set_title('üìâ Training Progress')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Complete evaluation visualizations generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8fc30a",
   "metadata": {},
   "source": [
    "## üéâ Project Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final project summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ NEURAL NETWORK PROJECT COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìä PROJECT STATISTICS:\")\n",
    "print(f\"   üìÅ Dataset size: {len(df)} samples\")\n",
    "print(f\"   üéØ Features used: {len(feature_cols)}\")\n",
    "print(f\"   üöÇ Training samples: {len(X_train)}\")\n",
    "print(f\"   üß™ Test samples: {len(X_test)}\")\n",
    "print(f\"   üß† Model parameters: {model.count_params():,}\")\n",
    "\n",
    "print(\"\\nüèÜ FINAL PERFORMANCE:\")\n",
    "print(f\"   üìà Test R¬≤: {test_r2:.3f}\")\n",
    "print(f\"   üìä Test MAE: {test_mae:.2f}\")\n",
    "print(f\"   üéØ Test RMSE: {np.sqrt(test_mse):.2f}\")\n",
    "\n",
    "print(\"\\nüöÄ WHAT WAS ACCOMPLISHED:\")\n",
    "print(\"   ‚úÖ Data exploration and visualization\")\n",
    "print(\"   ‚úÖ Feature engineering and preprocessing\")\n",
    "print(\"   ‚úÖ Neural network architecture design\")\n",
    "print(\"   ‚úÖ Model training with regularization\")\n",
    "print(\"   ‚úÖ Comprehensive performance evaluation\")\n",
    "print(\"   ‚úÖ Advanced visualizations and insights\")\n",
    "\n",
    "print(\"\\nüîÆ NEXT STEPS:\")\n",
    "print(\"   üéØ Fine-tune hyperparameters for better performance\")\n",
    "print(\"   üìä Try different neural network architectures\")\n",
    "print(\"   üîç Analyze feature importance in more detail\")\n",
    "print(\"   üíæ Save and deploy the model for production use\")\n",
    "print(\"   üìà Collect more data for improved accuracy\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS:\")\n",
    "if test_r2 > 0.7:\n",
    "    print(\"   üåü Your neural network shows excellent predictive performance!\")\n",
    "    print(\"   üéØ The model successfully captures appliance energy patterns.\")\n",
    "else:\n",
    "    print(\"   üìä Your neural network shows good learning capability.\")\n",
    "    print(\"   üîß Consider more data or feature engineering for improvement.\")\n",
    "\n",
    "print(f\"\\nüì± Model ready for appliance energy prediction!\")\n",
    "print(f\"üéØ Input {len(feature_cols)} features ‚Üí Get energy consumption prediction\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ SUCCESS! Your complete neural network pipeline is ready!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
